# For example, type install.packages("knitr") in the console to install the knitr package.
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h', fig.align = 'center')
knitr::opts_chunk$set(fig.cap = "",  fig.path = "Plot")
library(knitr)
library(dplyr)
library(arm)
library(pROC)
library(tidyverse)
library(MASS)
library(tigerstats)
library(leaps)
library(car)
library(rms)
require(caret)
require(e1071)
library(lme4)
library(lattice)
library(broom)
library(boot)
library(ggplot2)
library(cobalt)
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
require(MCMCpack)
library(abind)
library(matrixStats)
library(truncnorm)
library(mvtnorm)
library(MCMCpack)
library(mnormt)
library(coda)
library(NPBayesImputeCat)
# load dataset: df
load('../../Datasets/ordinalPUMS.Rdata')
# take 10,000 samples: df
set.seed(0)
n = 10000
sample <- sample(nrow(df), size = 10000)
df <- df[sample,]
# create MCAR scneario with 30% chance of missing: df_observed
missing_prob = 0.3
df_observed <- df
missing_col = c(1,3,7,9,10,11)
for (col in missing_col) {
missing_ind <- rbernoulli(n,p = missing_prob)
df_observed[missing_ind, col] <- NA
}
N = 40
Mon = 2000
B = 300
thin.int = 5
# 1. Create and initialize the Rcpp_Lcm model object
model = CreateModel(X = df_observed, MCZ = NULL, K = N, Nmax = 0,
aalpha = 0.25, balpha = 0.25, seed = 0)
# 2. Set tracer
model$SetTrace(c('k_star', 'psi', 'ImputedX', 'alpha'),Mon)
# 3. Run model using Run(burnin, iter, thinning)
model$Run(B,Mon,thin.int)
# Extract results
output <- model$GetTrace()
k_star <- output$k_star
psi <- output$psi
imputed_df <- output$ImputedX
alpha <- output$alpha
#retrieve parameters from the final iteration
result <- model$snapshot
#convert ImputedX matrix to dataframe, using proper factors/names etc.
ImputedX <- GetDataFrame(result$ImputedX,df)
for (var_index in missing_col) {
y_original = df[,var_index]
original_pmf = table(y_original)/length(y_original)
# Observed distribution
missing_indicator = is.na(df_observed)[,var_index]
y_observed = y_original[!missing_indicator]
observed_pmf = table(y_observed)/length(y_observed)
# Extract variable from imputed data
imputed_pmf = table(imputed_df[,seq(var_index, dim(imputed_df)[2], dim(df)[2])])
imputed_pmf = imputed_pmf/sum(imputed_pmf)
results = rbind(original_pmf,observed_pmf,imputed_pmf)
colnames(results)<- 1:dim(imputed_pmf)
barplot(results, xlab = 'Category', beside = TRUE,
legend = TRUE,
main = paste('Blocked Gibbs Sampling Assessment:', colnames(df)[var_index]))
}
# The number of clusters/latent groups used
plot(1:length(k_star), k_star, xlab = 'trials',
ylab = 'number of active clusters',
main = 'Number of clusters used over time', ylim = c(0,40))
# sampled alpha value for the stick breaking process
plot(1:length(alpha), alpha, xlab = 'trials',
ylab = 'alpha', type = 'l',
main = 'alpha value for the stick breaking process')
# load dataset: df
load('../../Datasets/ordinalPUMS.Rdata')
# take 10,000 samples: df
set.seed(0)
n = 10000
sample <- sample(nrow(df), size = 10000)
df <- df[sample,]
# create MCAR scneario with 30% chance of missing: df_observed
missing_prob = 0.3
df_observed <- df
missing_col = c(1,3,7,9,10,11)
for (col in missing_col) {
missing_ind <- rbernoulli(n,p = missing_prob)
df_observed[missing_ind, col] <- NA
}
# load dataset: df
load('../../Datasets/ordinalPUMS.Rdata')
# take 10,000 samples: df
set.seed(0)
n = 10000
sample <- sample(nrow(df), size = 10000)
df <- df[sample,]
# create MCAR scneario with 30% chance of missing: df_observed
missing_prob = 0.3
df_observed <- df
missing_col = c(1,3,7,9,10,11)
for (col in missing_col) {
missing_ind <- rbernoulli(n,p = missing_prob)
df_observed[missing_ind, col] <- NA
}
N = 40
Mon = 3000
B = 3000
thin.int = 5
# 1. Create and initialize the Rcpp_Lcm model object
model = CreateModel(X = df_observed, MCZ = NULL, K = N, Nmax = 0,
aalpha = 0.25, balpha = 0.25, seed = 0)
# 2. Set tracer
model$SetTrace(c('k_star', 'psi', 'ImputedX', 'alpha'),Mon)
# 3. Run model using Run(burnin, iter, thinning)
model$Run(B,Mon,thin.int)
# Extract results
output <- model$GetTrace()
k_star <- output$k_star
psi <- output$psi
imputed_df <- output$ImputedX
alpha <- output$alpha
#retrieve parameters from the final iteration
result <- model$snapshot
#convert ImputedX matrix to dataframe, using proper factors/names etc.
ImputedX <- GetDataFrame(result$ImputedX,df)
for (var_index in missing_col) {
y_original = df[,var_index]
original_pmf = table(y_original)/length(y_original)
# Observed distribution
missing_indicator = is.na(df_observed)[,var_index]
y_observed = y_original[!missing_indicator]
observed_pmf = table(y_observed)/length(y_observed)
# Extract variable from imputed data
imputed_pmf = table(imputed_df[,seq(var_index, dim(imputed_df)[2], dim(df)[2])])
imputed_pmf = imputed_pmf/sum(imputed_pmf)
results = rbind(original_pmf,observed_pmf,imputed_pmf)
colnames(results)<- 1:dim(imputed_pmf)
barplot(results, xlab = 'Category', beside = TRUE,
legend = TRUE,
main = paste('Blocked Gibbs Sampling Assessment:', colnames(df)[var_index]))
}
# The number of clusters/latent groups used
plot(1:length(k_star), k_star, xlab = 'trials',
ylab = 'number of active clusters',
main = 'Number of clusters used over time', ylim = c(0,40))
# sampled alpha value for the stick breaking process
plot(1:length(alpha), alpha, xlab = 'trials',
ylab = 'alpha', type = 'l',
main = 'alpha value for the stick breaking process')
combinations = combn(1:11, 2)
original_dist = c()
imputed_dist = c()
levels = c(7,7,7,19,5,4,7,2,17,3,13)
for (i in 1:(dim(combinations)[2])) {
variables = combinations[, i]
# Compute the joint pmf in the original dataframe without missing values
original_pmf = table(df[,variables])
original_pmf = original_pmf/sum(original_pmf)
# Compute the joint pmf in the imputed dataset and average over imputations
imputed_pmf = table(factor(imputed_df[,seq(variables[1],
dim(imputed_df)[2], dim(df)[2])],
levels = 0:(levels[variables[1]]-1)),
factor(imputed_df[,seq(variables[2],
dim(imputed_df)[2], dim(df)[2])] ,
levels = 0:(levels[variables[2]]-1)))
imputed_pmf = imputed_pmf/sum(imputed_pmf)
original_dist = rbind(original_dist, matrix(original_pmf, ncol = 1))
imputed_dist = rbind(imputed_dist, matrix(imputed_pmf, ncol = 1))
}
# Calculate r square which is just correlation
plot(original_dist, imputed_dist,
xlab = 'Original joint pmf', ylab = 'Imputed joint pmf',
main = "Bivariate pmf")
abline(0,1, col = 'gray')
abline(0,1.1, col = 'red')
abline(0, 0.9, col = 'red')
combinations = combn(1:11, 3)
original_dist = c()
imputed_dist = c()
levels = c(7,7,7,19,5,4,7,2,17,3,13)
for (i in 1:(dim(combinations)[2])) {
variables = combinations[, i]
# Compute the joint pmf in the original dataframe without missing values
original_pmf = table(df[,variables])
original_pmf = original_pmf/sum(original_pmf)
# Compute the joint pmf in the imputed dataset and average over imputations
imputed_pmf = table(factor(imputed_df[,seq(variables[1],
dim(imputed_df)[2], dim(df)[2])],
levels = 0:(levels[variables[1]]-1)),
factor(imputed_df[,seq(variables[2],
dim(imputed_df)[2], dim(df)[2])] ,
levels = 0:(levels[variables[2]]-1)),
factor(imputed_df[,seq(variables[3],
dim(imputed_df)[2], dim(df)[2])] ,
levels = 0:(levels[variables[3]]-1)))
imputed_pmf = imputed_pmf/sum(imputed_pmf)
original_dist = rbind(original_dist, matrix(original_pmf, ncol = 1))
imputed_dist = rbind(imputed_dist, matrix(imputed_pmf, ncol = 1))
}
# Calculate r square which is just correlation
plot(original_dist, imputed_dist,
xlab = 'Original joint pmf', ylab = 'Imputed joint pmf',
main = 'Trivariate pmf')
abline(0,1, col = 'gray')
abline(0,1.1, col = 'red')
abline(0, 0.9, col = 'red')
# DO NOT ALTER CODE IN THIS CHUNK
# The very first time you use this R markdown file, you should install each of the packages below.
# The same goes for other packages you might decide to use
# Remember that you only need to install each R package once in R (ever -- unless you change computers).
# All you need to do whenever you need to use the package again (after restarting the R session),
# is to use the library function to call the package.
# For example, type install.packages("knitr") in the console to install the knitr package.
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h', fig.align = 'center')
knitr::opts_chunk$set(fig.cap = "",  fig.path = "Plot")
library(knitr)
library(dplyr)
library(arm)
library(pROC)
library(tidyverse)
library(MASS)
library(tigerstats)
library(leaps)
library(car)
library(rms)
require(caret)
require(e1071)
library(lme4)
library(lattice)
library(broom)
library(boot)
library(ggplot2)
library(cobalt)
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
require(MCMCpack)
library(abind)
library(matrixStats)
library(truncnorm)
library(mvtnorm)
library(MCMCpack)
library(mnormt)
library(coda)
library(missForest)
# load dataset: df
load('../../Datasets/ordinalPUMS.Rdata')
# take 10,000 samples: df
set.seed(0)
n = 10000
sample <- sample(nrow(df), size = 10000)
df <- df[sample,]
# create MCAR scneario with 30% chance of missing: df_observed
missing_prob = 0.3
df_observed <- df
missing_col = c(1,3,7,9,10,11)
for (col in missing_col) {
missing_ind <- rbernoulli(n,p = missing_prob)
df_observed[missing_ind, col] <- NA
}
# load dataset: df
load('../../Datasets/ordinalPUMS.Rdata')
# take 10,000 samples: df
set.seed(0)
n = 10000
sample <- sample(nrow(df), size = 10000)
df <- df[sample,]
# create MCAR scneario with 30% chance of missing: df_observed
missing_prob = 0.3
df_observed <- df
missing_col = c(1,3,7,9,10,11)
for (col in missing_col) {
missing_ind <- rbernoulli(n,p = missing_prob)
df_observed[missing_ind, col] <- NA
}
df.imp <- missForest(df_observed, verbose = FALSE)
d1 <-  df.imp$ximp
df.imp <- missForest(df_observed, verbose = FALSE)
d2 <-  df.imp$ximp
df.imp <- missForest(df_observed, verbose = FALSE)
d3 <-  df.imp$ximp
df.imp <- missForest(df_observed, verbose = FALSE)
d4 <-  df.imp$ximp
df.imp <- missForest(df_observed, verbose = FALSE)
d5 <-  df.imp$ximp
imputed_sets = rbind(d1, d2, d3, d4, d5)
for (var_index in missing_col) {
y_original = df[,var_index]
original_pmf = table(y_original)/length(y_original)
# Observed distribution
missing_indicator = is.na(df_observed)[,var_index]
y_observed = y_original[!missing_indicator]
observed_pmf = table(y_observed)/length(y_observed)
# Extract variable from imputed data
sample_estimate1 = table(d1[,var_index])/length(d1[,var_index])
sample_estimate2 = table(d2[,var_index])/length(d2[,var_index])
sample_estimate3 = table(d3[,var_index])/length(d3[,var_index])
sample_estimate4 = table(d4[,var_index])/length(d4[,var_index])
sample_estimate5 = table(d5[,var_index])/length(d5[,var_index])
imputed_pmf = (sample_estimate1 + sample_estimate2 + sample_estimate3 +
sample_estimate4 + sample_estimate5)/5
results = rbind(original_pmf,observed_pmf,imputed_pmf)
colnames(results)<- 1:dim(imputed_pmf)
barplot(results, xlab = 'Category', beside = TRUE,
legend = TRUE,
main = paste('MICE:', colnames(df)[var_index]))
}
combinations = combn(1:11, 2)
original_dist = c()
imputed_dist = c()
for (i in 1:(dim(combinations)[2])) {
variables = combinations[, i]
# Compute the joint pmf in the original dataframe without missing values
original_pmf = table(df[,variables])
original_pmf = original_pmf/sum(original_pmf)
# Compute the joint pmf in the imputed dataset and average over imputations
imputed_pmf = table(imputed_sets[,variables])
imputed_pmf = imputed_pmf/sum(imputed_pmf)
original_dist = rbind(original_dist, matrix(original_pmf, ncol = 1))
imputed_dist = rbind(imputed_dist, matrix(imputed_pmf, ncol = 1))
}
# Calculate r square which is just correlation
plot(original_dist, imputed_dist,
xlab = 'Original joint pmf', ylab = 'Imputed joint pmf',
main = 'Bivariate pmf')
abline(0,1, col = 'gray')
abline(0,1.1, col = 'red')
abline(0, 0.9, col = 'red')
combinations = combn(1:11, 3)
original_dist = c()
imputed_dist = c()
for (i in 1:(dim(combinations)[2])) {
variables = combinations[, i]
# Compute the joint pmf in the original dataframe without missing values
original_pmf = table(df[,variables])
original_pmf = original_pmf/sum(original_pmf)
# Compute the joint pmf in the imputed dataset and average over imputations
imputed_pmf = table(imputed_sets[,variables])
imputed_pmf = imputed_pmf/sum(imputed_pmf)
original_dist = rbind(original_dist, matrix(original_pmf, ncol = 1))
imputed_dist = rbind(imputed_dist, matrix(imputed_pmf, ncol = 1))
}
# Calculate r square which is just correlation
plot(original_dist, imputed_dist,
xlab = 'Original joint pmf', ylab = 'Imputed joint pmf',
main = 'Trivariate pmf')
abline(0,1, col = 'gray')
abline(0,1.1, col = 'red')
abline(0, 0.9, col = 'red')
# calculate rmse
numeric_df = sapply(df, as.numeric)
normalized_df = t(t(numeric_df-1)/(apply(numeric_df, MARGIN = 2, FUN = max)-1))
numeric_impute = sapply(d1, as.numeric)
normalized_impute = t(t(numeric_impute-1)/(apply(numeric_df, MARGIN = 2, FUN = max)-1))
missing_matrix = is.na(df_observed)
rmse = sqrt(sum((normalized_df[missing_matrix] - normalized_impute[missing_matrix])^2)/sum(missing_matrix))
print('rmse')
rmse
# DO NOT ALTER CODE IN THIS CHUNK
# The very first time you use this R markdown file, you should install each of the packages below.
# The same goes for other packages you might decide to use
# Remember that you only need to install each R package once in R (ever -- unless you change computers).
# All you need to do whenever you need to use the package again (after restarting the R session),
# is to use the library function to call the package.
# For example, type install.packages("knitr") in the console to install the knitr package.
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h', fig.align = 'center')
knitr::opts_chunk$set(fig.cap = "",  fig.path = "Plot")
library(knitr)
library(dplyr)
library(arm)
library(pROC)
library(tidyverse)
library(MASS)
library(tigerstats)
library(leaps)
library(car)
library(rms)
require(caret)
require(e1071)
library(lme4)
library(lattice)
library(broom)
library(boot)
library(ggplot2)
library(cobalt)
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
require(MCMCpack)
library(abind)
library(matrixStats)
library(truncnorm)
library(mvtnorm)
library(MCMCpack)
library(mnormt)
library(coda)
# load dataset: df
load('../../Datasets/ordinalPUMS.Rdata')
# take 10,000 samples: df
set.seed(0)
n = 10000
sample <- sample(nrow(df), size = 10000)
df <- df[sample,]
# create MCAR scneario with 30% chance of missing: df_observed
missing_prob = 0.3
df_observed <- df
missing_col = c(1,3,7,9,10,11)
for (col in missing_col) {
missing_ind <- rbernoulli(n,p = missing_prob)
df_observed[missing_ind, col] <- NA
}
library(mice)
imputed_df <-  mice(df_observed,m=5,print=F)
d1 <-  complete(imputed_df, 1)
d2 <-  complete(imputed_df, 2)
d3 <-  complete(imputed_df, 3)
d4 <-  complete(imputed_df, 4)
d5 <-  complete(imputed_df, 5)
imputed_sets = rbind(d1, d2, d3, d4, d5)
for (var_index in missing_col) {
y_original = df[,var_index]
original_pmf = table(y_original)/length(y_original)
# Observed distribution
missing_indicator = is.na(df_observed)[,var_index]
y_observed = y_original[!missing_indicator]
observed_pmf = table(y_observed)/length(y_observed)
# Extract variable from imputed data
sample_estimate1 = table(d1[,var_index])/length(d1[,var_index])
sample_estimate2 = table(d2[,var_index])/length(d2[,var_index])
sample_estimate3 = table(d3[,var_index])/length(d3[,var_index])
sample_estimate4 = table(d4[,var_index])/length(d4[,var_index])
sample_estimate5 = table(d5[,var_index])/length(d5[,var_index])
imputed_pmf = (sample_estimate1 + sample_estimate2 + sample_estimate3 +
sample_estimate4 + sample_estimate5)/5
results = rbind(original_pmf,observed_pmf,imputed_pmf)
colnames(results)<- 1:dim(imputed_pmf)
barplot(results, xlab = 'Category', beside = TRUE,
legend = TRUE,
main = paste('MICE:', colnames(df)[var_index]))
}
combinations = combn(1:11, 2)
original_dist = c()
imputed_dist = c()
for (i in 1:(dim(combinations)[2])) {
variables = combinations[, i]
# Compute the joint pmf in the original dataframe without missing values
original_pmf = table(df[,variables])
original_pmf = original_pmf/sum(original_pmf)
# Compute the joint pmf in the imputed dataset and average over imputations
imputed_pmf = table(imputed_sets[,variables])
imputed_pmf = imputed_pmf/sum(imputed_pmf)
original_dist = rbind(original_dist, matrix(original_pmf, ncol = 1))
imputed_dist = rbind(imputed_dist, matrix(imputed_pmf, ncol = 1))
}
# Calculate r square which is just correlation
plot(original_dist, imputed_dist,
xlab = 'Original joint pmf', ylab = 'Imputed joint pmf',
main = 'Bivariate pmf')
abline(0,1, col = 'gray')
abline(0,1.1, col = 'red')
abline(0, 0.9, col = 'red')
combinations = combn(1:11, 3)
original_dist = c()
imputed_dist = c()
for (i in 1:(dim(combinations)[2])) {
variables = combinations[, i]
# Compute the joint pmf in the original dataframe without missing values
original_pmf = table(df[,variables])
original_pmf = original_pmf/sum(original_pmf)
# Compute the joint pmf in the imputed dataset and average over imputations
imputed_pmf = table(imputed_sets[,variables])
imputed_pmf = imputed_pmf/sum(imputed_pmf)
original_dist = rbind(original_dist, matrix(original_pmf, ncol = 1))
imputed_dist = rbind(imputed_dist, matrix(imputed_pmf, ncol = 1))
}
# Calculate r square which is just correlation
plot(original_dist, imputed_dist,
xlab = 'Original joint pmf', ylab = 'Imputed joint pmf',
main = 'Trivariate pmf')
abline(0,1, col = 'gray')
abline(0,1.1, col = 'red')
abline(0, 0.9, col = 'red')
# calculate rmse
numeric_df = sapply(df, as.numeric)
normalized_df = t(t(numeric_df-1)/(apply(numeric_df, MARGIN = 2, FUN = max)-1))
numeric_impute = sapply(d1, as.numeric)
normalized_impute = t(t(numeric_impute-1)/(apply(numeric_df, MARGIN = 2, FUN = max)-1))
missing_matrix = is.na(df_observed)
rmse = sqrt(sum((normalized_df[missing_matrix] - normalized_impute[missing_matrix])^2)/sum(missing_matrix))
rmse
