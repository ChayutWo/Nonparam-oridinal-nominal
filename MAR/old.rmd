
---
title: "Testing different imputation methods on PUMS (MAR)"
output:
  pdf_document: default
  html_document:
    highlight: pygments
    theme: spacelab
---

```{r setup, echo =FALSE, include=FALSE}
# DO NOT ALTER CODE IN THIS CHUNK
# The very first time you use this R markdown file, you should install each of the packages below.
# The same goes for other packages you might decide to use
# Remember that you only need to install each R package once in R (ever -- unless you change computers).
# All you need to do whenever you need to use the package again (after restarting the R session),
# is to use the library function to call the package.
# For example, type install.packages("knitr") in the console to install the knitr package. 
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h', fig.align = 'center')
knitr::opts_chunk$set(fig.cap = "",  fig.path = "Plot")
library(knitr)
library(dplyr)
library(arm)
library(pROC)
library(tidyverse)
library(MASS)
library(tigerstats)
library(leaps)
library(car)
library(rms)
require(caret)
require(e1071)
library(lme4) 
library(lattice)
library(broom)
library(boot)
library(ggplot2)
library(cobalt)
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
require(MCMCpack)
library(abind)
library(matrixStats)
library(truncnorm)
library(mvtnorm)
library(MCMCpack)
library(mnormt)
library(coda)
```

* * *
```{r}
# load dataset: df
load('../Datasets/ordinalPUMS.Rdata')

# take 10,000 samples: df
set.seed(0)
n = 10000
sample <- sample(nrow(df), size = 10000)
df <- df[sample,]

# create MCAR scneario with 30% chance of missing: df_observed
missing_prob = 0.3
df_observed <- df
missing_col = c(1,3,7,9,10,11)

# Make VEH and WKL MCAR
missing_col_MCAR = c(1,10)
for (col in missing_col_MCAR) {
  missing_ind <- rbernoulli(n,p = missing_prob)
  df_observed[missing_ind, col] <- NA
}

# Make the rest MAR
numeric_df = sapply(df, as.numeric)
normalized_df = t(t(numeric_df-1)/(apply(numeric_df, MARGIN = 2, FUN = max)-1))
missing_col_MAR = c(3,7,9,11)
fully_observed_col = c(2,4,5,6,8)
beta_NP = c(-0.05, -1.5, 0.6, -2, -0.05)
beta0_NP = -0.05
beta_SCHL = c(-3, 3, -0.75, 0.05, -0.2)
beta0_SCHL = 0.05
beta_AGEP = c(0.05, -0.2, 0.05, -1.25, 1)
beta0_AGEP = -0.05
beta_PINCP = c(3, -0.05, -2.5, 0.05, -1)
beta0_PINCP = -0.05

# missing probability for NP
prob_NP = apply(t(t(normalized_df[, fully_observed_col])*beta_NP)+beta0_NP, MARGIN = 1, sum)
prob_NP = exp(prob_NP)/(exp(prob_NP)+1)
indicator = rbernoulli(n, p = prob_NP)
df_observed[indicator, missing_col_MAR[1]] <- NA

# missing probability for SCHL
prob_SCHL = apply(t(t(normalized_df[, fully_observed_col])*beta_SCHL)+beta0_SCHL, MARGIN = 1, sum)
prob_SCHL = exp(prob_SCHL)/(exp(prob_SCHL)+1)
indicator = rbernoulli(n, p = prob_SCHL)
df_observed[indicator, missing_col_MAR[2]] <- NA

# missing probability for AGEP
prob_AGEP = apply(t(t(normalized_df[, fully_observed_col])*beta_AGEP)+beta0_AGEP, MARGIN = 1, sum)
prob_AGEP = exp(prob_AGEP)/(exp(prob_AGEP)+1)
indicator = rbernoulli(n, p = prob_AGEP)
df_observed[indicator, missing_col_MAR[3]] <- NA

# missing probability for PINCP
prob_PINCP = apply(t(t(normalized_df[, fully_observed_col])*beta_PINCP)+beta0_PINCP, MARGIN = 1, sum)
prob_PINCP = exp(prob_PINCP)/(exp(prob_PINCP)+1)
indicator = rbernoulli(n, p = prob_PINCP)
df_observed[indicator, missing_col_MAR[4]] <- NA

# 30.58% missing
apply(is.na(df_observed), MARGIN = 2, mean)
```


Histogram for univariate distribution
```{r, echo = FALSE}
for (var_index in missing_col) {
  y_original = df[,var_index]
  original_pmf = table(y_original)/length(y_original)
  
  # Observed distribution
  missing_indicator = is.na(df_observed)[,var_index]
  y_observed = y_original[!missing_indicator]
  observed_pmf = table(y_observed)/length(y_observed)
  

  results = rbind(original_pmf,observed_pmf)
  colnames(results)<- 1:dim(observed_pmf)
  barplot(results, xlab = 'Category', beside = TRUE, 
          legend = TRUE, 
          main = paste('Histogram:', colnames(df)[var_index]))
}
```

Assess bivariate joint distribution
```{r, echo = FALSE}
combinations = combn(1:11, 2)
original_dist = c()
observed_dist = c()
for (i in 1:(dim(combinations)[2])) {
  variables = combinations[, i]
  if (variables[1] %in% missing_col_MAR | variables[2] %in% missing_col_MAR) {
    # Compute the joint pmf in the original dataframe without missing values
    original_pmf = table(df[,variables])
    original_pmf = original_pmf/sum(original_pmf)
        
    # Compute the joint pmf in the imputed dataset and average over imputations
    observed_pmf = table(df_observed[,variables])
    observed_pmf = observed_pmf/sum(observed_pmf)
    
    original_dist = rbind(original_dist, matrix(original_pmf, ncol = 1))
    observed_dist = rbind(observed_dist, matrix(observed_pmf, ncol = 1))
  }
}

plot(original_dist, observed_dist, 
     xlab = 'Original joint pmf', ylab = 'Observed joint pmf', 
     main = "Bivariate pmf", ylim = c(0,0.4), xlim = c(0,0.4))
abline(0,1, col = 'gray')
abline(0,1.1, col = 'red')
abline(0, 0.9, col = 'red')
```

Assess trivariate joint distribution
```{r, echo = FALSE}
combinations = combn(1:11, 3)
original_dist = c()
observed_dist = c()
n= 0
for (i in 1:(dim(combinations)[2])) {
  variables = combinations[, i]
  if (variables[1] %in% missing_col_MAR | variables[2] %in% missing_col_MAR | variables[3] %in% missing_col_MAR) {
    # Compute the joint pmf in the original dataframe without missing values
    original_pmf = table(df[,variables])
    original_pmf = original_pmf/sum(original_pmf)
        
    # Compute the joint pmf in the imputed dataset and average over imputations
    observed_pmf = table(df_observed[,variables])
    observed_pmf = observed_pmf/sum(observed_pmf)
    
    original_dist = rbind(original_dist, matrix(original_pmf, ncol = 1))
    observed_dist = rbind(observed_dist, matrix(observed_pmf, ncol = 1))
  }
}

plot(original_dist, observed_dist, 
     xlab = 'Original joint pmf', ylab = 'Observed joint pmf', 
     main = "Trivariate pmf", ylim = c(0,0.4), xlim = c(0,0.4))
abline(0,1, col = 'gray')
abline(0,1.1, col = 'red')
abline(0, 0.9, col = 'red')
```
* * *



