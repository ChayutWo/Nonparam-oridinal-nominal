
---
title: "Testing different imputation methods on PUMS (MAR) - RandomForest"
output:
  pdf_document: default
  html_document:
    highlight: pygments
    theme: spacelab
---

```{r setup, echo =FALSE, include=FALSE}
# DO NOT ALTER CODE IN THIS CHUNK
# The very first time you use this R markdown file, you should install each of the packages below.
# The same goes for other packages you might decide to use
# Remember that you only need to install each R package once in R (ever -- unless you change computers).
# All you need to do whenever you need to use the package again (after restarting the R session),
# is to use the library function to call the package.
# For example, type install.packages("knitr") in the console to install the knitr package. 
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h', fig.align = 'center')
knitr::opts_chunk$set(fig.cap = "",  fig.path = "Plot")
library(knitr)
library(dplyr)
library(arm)
library(pROC)
library(tidyverse)
library(MASS)
library(tigerstats)
library(leaps)
library(car)
library(rms)
require(caret)
require(e1071)
library(lme4) 
library(lattice)
library(broom)
library(boot)
library(ggplot2)
library(cobalt)
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
require(MCMCpack)
library(abind)
library(matrixStats)
library(truncnorm)
library(mvtnorm)
library(MCMCpack)
library(mnormt)
library(coda)
library(missForest)
```

* * *
```{r}
# load dataset: df
load('../../Datasets/ordinalPUMS.Rdata')

# take 10,000 samples: df
set.seed(0)
n = 10000
sample <- sample(nrow(df), size = 10000)
df <- df[sample,]

# create MCAR scneario with 30% chance of missing: df_observed
missing_prob = 0.3
df_observed <- df
missing_col = c(1,3,7,9,10,11)

# Make VEH and WKL MCAR
missing_col_MCAR = c(1,10)
for (col in missing_col_MCAR) {
  missing_ind <- rbernoulli(n,p = missing_prob)
  df_observed[missing_ind, col] <- NA
}

# Make the rest MAR
numeric_df = sapply(df, as.numeric)
normalized_df = t(t(numeric_df-1)/(apply(numeric_df, MARGIN = 2, FUN = max)-1))
missing_col_MAR = c(3,7,9,11)
fully_observed_col = c(2,4,5,6,8)
beta_NP = c(-0.05, -1.5, 0.6, -2, -0.05)
beta0_NP = -0.05
beta_SCHL = c(-3, 3, -0.75, 0.05, -0.2)
beta0_SCHL = 0.05
beta_AGEP = c(0.05, -0.2, 0.05, -1.25, 1)
beta0_AGEP = -0.05
beta_PINCP = c(3, -0.05, -2.5, 0.05, -1)
beta0_PINCP = -0.05

# missing probability for NP
prob_NP = apply(t(t(normalized_df[, fully_observed_col])*beta_NP)+beta0_NP, MARGIN = 1, sum)
prob_NP = exp(prob_NP)/(exp(prob_NP)+1)
indicator = rbernoulli(n, p = prob_NP)
df_observed[indicator, missing_col_MAR[1]] <- NA

# missing probability for SCHL
prob_SCHL = apply(t(t(normalized_df[, fully_observed_col])*beta_SCHL)+beta0_SCHL, MARGIN = 1, sum)
prob_SCHL = exp(prob_SCHL)/(exp(prob_SCHL)+1)
indicator = rbernoulli(n, p = prob_SCHL)
df_observed[indicator, missing_col_MAR[2]] <- NA

# missing probability for AGEP
prob_AGEP = apply(t(t(normalized_df[, fully_observed_col])*beta_AGEP)+beta0_AGEP, MARGIN = 1, sum)
prob_AGEP = exp(prob_AGEP)/(exp(prob_AGEP)+1)
indicator = rbernoulli(n, p = prob_AGEP)
df_observed[indicator, missing_col_MAR[3]] <- NA

# missing probability for PINCP
prob_PINCP = apply(t(t(normalized_df[, fully_observed_col])*beta_PINCP)+beta0_PINCP, MARGIN = 1, sum)
prob_PINCP = exp(prob_PINCP)/(exp(prob_PINCP)+1)
indicator = rbernoulli(n, p = prob_PINCP)
df_observed[indicator, missing_col_MAR[4]] <- NA

# 30.58% missing
apply(is.na(df_observed), MARGIN = 2, mean)
```


### missForest

```{r, echo = TRUE, results='hide'}
df.imp <- missForest(df_observed, verbose = FALSE)
d1 <-  df.imp$ximp
df.imp <- missForest(df_observed, verbose = FALSE)
d2 <-  df.imp$ximp
df.imp <- missForest(df_observed, verbose = FALSE)
d3 <-  df.imp$ximp
df.imp <- missForest(df_observed, verbose = FALSE)
d4 <-  df.imp$ximp
df.imp <- missForest(df_observed, verbose = FALSE)
d5 <-  df.imp$ximp
imputed_sets = rbind(d1, d2, d3, d4, d5)
```


Diagnostics

```{r, echo = FALSE}
for (var_index in missing_col) {
  y_original = df[,var_index]
  original_pmf = table(y_original)/length(y_original)
  
  # Observed distribution
  missing_indicator = is.na(df_observed)[,var_index]
  y_observed = y_original[!missing_indicator]
  observed_pmf = table(y_observed)/length(y_observed)
  
  # Extract variable from imputed data
  sample_estimate1 = table(d1[,var_index])/length(d1[,var_index])
  sample_estimate2 = table(d2[,var_index])/length(d2[,var_index])
  sample_estimate3 = table(d3[,var_index])/length(d3[,var_index])
  sample_estimate4 = table(d4[,var_index])/length(d4[,var_index])
  sample_estimate5 = table(d5[,var_index])/length(d5[,var_index])
  
  imputed_pmf = (sample_estimate1 + sample_estimate2 + sample_estimate3 +
                   sample_estimate4 + sample_estimate5)/5
  
  results = rbind(original_pmf,observed_pmf,imputed_pmf)
  colnames(results)<- 1:dim(imputed_pmf)
  barplot(results, xlab = 'Category', beside = TRUE, 
          legend = TRUE, 
          main = paste('MICE:', colnames(df)[var_index]))
}
```


Assess bivariate joint distribution
```{r, echo = FALSE}
combinations = combn(1:11, 2)
original_dist = c()
imputed_dist = c()
for (i in 1:(dim(combinations)[2])) {
  variables = combinations[, i]
  # Compute the joint pmf in the original dataframe without missing values
  original_pmf = table(df[,variables])
  original_pmf = original_pmf/sum(original_pmf)
      
  # Compute the joint pmf in the imputed dataset and average over imputations
  imputed_pmf = table(imputed_sets[,variables])
  imputed_pmf = imputed_pmf/sum(imputed_pmf)
  
  original_dist = rbind(original_dist, matrix(original_pmf, ncol = 1))
  imputed_dist = rbind(imputed_dist, matrix(imputed_pmf, ncol = 1))
}

plot(original_dist, imputed_dist, 
     xlab = 'Original joint pmf', ylab = 'Imputed joint pmf', 
     main = 'Bivariate pmf')
abline(0,1, col = 'gray')
abline(0,1.1, col = 'red')
abline(0, 0.9, col = 'red')
```


Assess trivariate joint distribution
```{r, echo = FALSE}
combinations = combn(1:11, 3)
original_dist = c()
imputed_dist = c()
for (i in 1:(dim(combinations)[2])) {
  variables = combinations[, i]
  # Compute the joint pmf in the original dataframe without missing values
  original_pmf = table(df[,variables])
  original_pmf = original_pmf/sum(original_pmf)
      
  # Compute the joint pmf in the imputed dataset and average over imputations
  imputed_pmf = table(imputed_sets[,variables])
  imputed_pmf = imputed_pmf/sum(imputed_pmf)
  
  original_dist = rbind(original_dist, matrix(original_pmf, ncol = 1))
  imputed_dist = rbind(imputed_dist, matrix(imputed_pmf, ncol = 1))
}

plot(original_dist, imputed_dist, 
     xlab = 'Original joint pmf', ylab = 'Imputed joint pmf', 
     main = 'Trivariate pmf')
abline(0,1, col = 'gray')
abline(0,1.1, col = 'red')
abline(0, 0.9, col = 'red')
```

```{r, echo = FALSE}
# calculate rmse
numeric_df = sapply(df, as.numeric)
normalized_df = t(t(numeric_df-1)/(apply(numeric_df, MARGIN = 2, FUN = max)-1))
numeric_impute = sapply(d1, as.numeric)
normalized_impute = t(t(numeric_impute-1)/(apply(numeric_df, MARGIN = 2, FUN = max)-1))

missing_matrix = is.na(df_observed)

rmse = sqrt(sum((normalized_df[missing_matrix] - normalized_impute[missing_matrix])^2)/sum(missing_matrix))
print('rmse')
rmse
```

* * *



