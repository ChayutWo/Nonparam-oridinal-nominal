
---
title: "Testing different imputation methods on PUMS (MAR) - DPMPM"
output:
  pdf_document: default
  html_document:
    highlight: pygments
    theme: spacelab
---

```{r setup, echo =FALSE, include=FALSE}
# DO NOT ALTER CODE IN THIS CHUNK
# The very first time you use this R markdown file, you should install each of the packages below.
# The same goes for other packages you might decide to use
# Remember that you only need to install each R package once in R (ever -- unless you change computers).
# All you need to do whenever you need to use the package again (after restarting the R session),
# is to use the library function to call the package.
# For example, type install.packages("knitr") in the console to install the knitr package. 
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h', fig.align = 'center')
knitr::opts_chunk$set(fig.cap = "",  fig.path = "Plot")
library(knitr)
library(dplyr)
library(arm)
library(pROC)
library(tidyverse)
library(MASS)
library(tigerstats)
library(leaps)
library(car)
library(rms)
require(caret)
require(e1071)
library(lme4) 
library(lattice)
library(broom)
library(boot)
library(ggplot2)
library(cobalt)
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
require(MCMCpack)
library(abind)
library(matrixStats)
library(truncnorm)
library(mvtnorm)
library(MCMCpack)
library(mnormt)
library(coda)
library(NPBayesImputeCat)
```

* * *
```{r}
# load dataset: df
load('../../Datasets/ordinalPUMS.Rdata')

# take 10,000 samples: df
set.seed(0)
n = 10000
sample <- sample(nrow(df), size = 10000)
df <- df[sample,]

# create MCAR scneario with 30% chance of missing: df_observed
missing_prob = 0.3
df_observed <- df
missing_col = c(1,3,7,9,10,11)

# Make VEH and WKL MCAR
missing_col_MCAR = c(1,10)
for (col in missing_col_MCAR) {
  missing_ind <- rbernoulli(n,p = missing_prob)
  df_observed[missing_ind, col] <- NA
}

# Make the rest MAR
numeric_df = sapply(df, as.numeric)
normalized_df = t(t(numeric_df-1)/(apply(numeric_df, MARGIN = 2, FUN = max)-1))
missing_col_MAR = c(3,7,9,11)
fully_observed_col = c(2,4,5,6,8)
beta_NP = c(-0.05, -1.5, 0.6, -2, -0.05)
beta0_NP = -0.05
beta_SCHL = c(-3, 3, -0.75, 0.05, -0.2)
beta0_SCHL = 0.05
beta_AGEP = c(0.05, -0.2, 0.05, -1.25, 1)
beta0_AGEP = -0.05
beta_PINCP = c(3, -0.05, -2.5, 0.05, -1)
beta0_PINCP = -0.05

# missing probability for NP
prob_NP = apply(t(t(normalized_df[, fully_observed_col])*beta_NP)+beta0_NP, MARGIN = 1, sum)
prob_NP = exp(prob_NP)/(exp(prob_NP)+1)
indicator = rbernoulli(n, p = prob_NP)
df_observed[indicator, missing_col_MAR[1]] <- NA

# missing probability for SCHL
prob_SCHL = apply(t(t(normalized_df[, fully_observed_col])*beta_SCHL)+beta0_SCHL, MARGIN = 1, sum)
prob_SCHL = exp(prob_SCHL)/(exp(prob_SCHL)+1)
indicator = rbernoulli(n, p = prob_SCHL)
df_observed[indicator, missing_col_MAR[2]] <- NA

# missing probability for AGEP
prob_AGEP = apply(t(t(normalized_df[, fully_observed_col])*beta_AGEP)+beta0_AGEP, MARGIN = 1, sum)
prob_AGEP = exp(prob_AGEP)/(exp(prob_AGEP)+1)
indicator = rbernoulli(n, p = prob_AGEP)
df_observed[indicator, missing_col_MAR[3]] <- NA

# missing probability for PINCP
prob_PINCP = apply(t(t(normalized_df[, fully_observed_col])*beta_PINCP)+beta0_PINCP, MARGIN = 1, sum)
prob_PINCP = exp(prob_PINCP)/(exp(prob_PINCP)+1)
indicator = rbernoulli(n, p = prob_PINCP)
df_observed[indicator, missing_col_MAR[4]] <- NA

# 30.58% missing
apply(is.na(df_observed), MARGIN = 2, mean)
```


### DPMPM

Multiple imputation using NPBayesImputeCat package

Ref: https://cran.r-project.org/web/packages/NPBayesImputeCat/NPBayesImputeCat.pdf

1. Create and initialize the Rcpp_Lcm model object using CreateModel with the following arguments:
  - X: dataframe to be imptuted = df
  - MCZ: dataframe with the definition of structural zero = NULL
  - K: the maximum number of mixture components = 40
  - Nmax: An upper truncation limit for the augmented sample size = 0
  - aalpha: the hyper parameter alpha in stick-breaking prior = 0.25
  - balpha: the hyper parameter beta in stick-breaking prior = 0.25
  - seed = 0

2. Set the tracer for the sampling process
  - k_star: the effective cluster number
  - psi: conditional multinomial probabilties
  - ImputedX: imputation result

3. Run the model using the method Run of Rcpp_Lcm class with the following arguments:
  - burnin = 10000
  - iter = 10000
  - thinning = 5

4. Obtain result

```{r, results = 'hide'}
N = 40
Mon = 10000
B = 10000
thin.int = 5

# 1. Create and initialize the Rcpp_Lcm model object
model = CreateModel(X = df_observed, MCZ = NULL, K = N, Nmax = 0,
                    aalpha = 0.25, balpha = 0.25, seed = 0)
# 2. Set tracer
model$SetTrace(c('k_star', 'psi', 'ImputedX', 'alpha'),Mon)

# 3. Run model using Run(burnin, iter, thinning)
model$Run(B,Mon,thin.int)
```


```{r}
# Extract results
output <- model$GetTrace()
k_star <- output$k_star
psi <- output$psi
imputed_df <- output$ImputedX
alpha <- output$alpha

#retrieve parameters from the final iteration 
result <- model$snapshot

#convert ImputedX matrix to dataframe, using proper factors/names etc. 
ImputedX <- GetDataFrame(result$ImputedX,df)
```

Diagnostics

```{r, echo = FALSE}
for (var_index in missing_col) {
  y_original = df[,var_index]
  original_pmf = table(y_original)/length(y_original)
  
  # Observed distribution
  missing_indicator = is.na(df_observed)[,var_index]
  y_observed = y_original[!missing_indicator]
  observed_pmf = table(y_observed)/length(y_observed)
  
  # Extract variable from imputed data
  imputed_pmf = table(imputed_df[,seq(var_index, dim(imputed_df)[2], dim(df)[2])])
  imputed_pmf = imputed_pmf/sum(imputed_pmf)
  
  results = rbind(original_pmf,observed_pmf,imputed_pmf)
  colnames(results)<- 1:dim(imputed_pmf)
  barplot(results, xlab = 'Category', beside = TRUE, 
          legend = TRUE, 
          main = paste('Blocked Gibbs Sampling Assessment:', colnames(df)[var_index]))
}
```


```{r, echo = FALSE}
# The number of clusters/latent groups used
plot(1:length(k_star), k_star, xlab = 'trials', 
     ylab = 'number of active clusters', 
     main = 'Number of clusters used over time', ylim = c(0,40))
```

```{r, echo = FALSE}
# sampled alpha value for the stick breaking process
plot(1:length(alpha), alpha, xlab = 'trials', 
     ylab = 'alpha', type = 'l',
     main = 'alpha value for the stick breaking process')
```

Assess bivariate joint distribution
```{r, echo = FALSE}
combinations = combn(1:11, 2)
original_dist = c()
imputed_dist = c()
levels = c(7,7,7,19,5,4,7,2,17,3,13)
for (i in 1:(dim(combinations)[2])) {
  variables = combinations[, i]
  # Compute the joint pmf in the original dataframe without missing values
  original_pmf = table(df[,variables])
  original_pmf = original_pmf/sum(original_pmf)
      
  # Compute the joint pmf in the imputed dataset and average over imputations
  imputed_pmf = table(factor(imputed_df[,seq(variables[1], 
                                                dim(imputed_df)[2], dim(df)[2])], 
                                levels = 0:(levels[variables[1]]-1)),
                      factor(imputed_df[,seq(variables[2], 
                                                dim(imputed_df)[2], dim(df)[2])] ,
                                levels = 0:(levels[variables[2]]-1)))
                      
  imputed_pmf = imputed_pmf/sum(imputed_pmf)
  
  original_dist = rbind(original_dist, matrix(original_pmf, ncol = 1))
  imputed_dist = rbind(imputed_dist, matrix(imputed_pmf, ncol = 1))
}

plot(original_dist, imputed_dist, 
     xlab = 'Original joint pmf', ylab = 'Imputed joint pmf', 
     main = "Bivariate pmf")
abline(0,1, col = 'gray')
abline(0,1.1, col = 'red')
abline(0, 0.9, col = 'red')
```

Assess trivariate joint distribution
```{r, echo = FALSE}
combinations = combn(1:11, 3)
original_dist = c()
imputed_dist = c()
levels = c(7,7,7,19,5,4,7,2,17,3,13)
for (i in 1:(dim(combinations)[2])) {
  variables = combinations[, i]
  # Compute the joint pmf in the original dataframe without missing values
  original_pmf = table(df[,variables])
  original_pmf = original_pmf/sum(original_pmf)
      
  # Compute the joint pmf in the imputed dataset and average over imputations
  imputed_pmf = table(factor(imputed_df[,seq(variables[1], 
                                                dim(imputed_df)[2], dim(df)[2])], 
                                levels = 0:(levels[variables[1]]-1)),
                      factor(imputed_df[,seq(variables[2], 
                                                dim(imputed_df)[2], dim(df)[2])] ,
                                levels = 0:(levels[variables[2]]-1)),
                      factor(imputed_df[,seq(variables[3], 
                                                dim(imputed_df)[2], dim(df)[2])] ,
                                levels = 0:(levels[variables[3]]-1)))
                      
  imputed_pmf = imputed_pmf/sum(imputed_pmf)
  
  original_dist = rbind(original_dist, matrix(original_pmf, ncol = 1))
  imputed_dist = rbind(imputed_dist, matrix(imputed_pmf, ncol = 1))
}

plot(original_dist, imputed_dist, 
     xlab = 'Original joint pmf', ylab = 'Imputed joint pmf', 
     main = 'Trivariate pmf')
abline(0,1, col = 'gray')
abline(0,1.1, col = 'red')
abline(0, 0.9, col = 'red')
```

* * *



