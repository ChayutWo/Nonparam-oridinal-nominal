library(lattice)
library(broom)
library(boot)
library(ggplot2)
library(cobalt)
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
require(MCMCpack)
library(abind)
library(matrixStats)
library(truncnorm)
library(mvtnorm)
library(MCMCpack)
library(mnormt)
essay=read.csv("essay.csv",header=FALSE)
grades=essay[,1:5]
char=essay[,7:12]
names(char)=c("WL","SqW","PC","PS","PP","SL")
p=2
R=3
d=p+R
n=nrow(essay)
x=matrix(0,n,p)
x[,1]=char$WL
x[,2]=(char$SqW)^2
y=matrix(0,n,R)
y[,1]=grades[,2]
y[,2]=grades[,3]
y[,3]=grades[,4]
####prior specification####
N=40
R.x=apply(x,2,max)-apply(x,2,min)
mid.x=(apply(x,2,max)+apply(x,2,min))/2
gamma1=c(-10000,-4:4,10000)
gamma2=c(-10000,-4:4,10000)
gamma3=c(-10000,-4:4,10000)
K=length(gamma1)-1
R.z=c(gamma1[K]-gamma1[2],gamma2[K]-gamma2[2],gamma3[K]-gamma3[2])
class(y)
class(y[,1])
# load dataset: df
load('../Datasets/ordinalPUMS.Rdata')
# take 10,000 samples: df
n = 10000
sample <- sample(nrow(df), size = 10000)
df <- df[sample,]
# create MCAR scneario with 30% chance of missing: df_observed
missing_prob = 0.3
df_observed <- df
missing_col = colnames(df)[c(1,3,5,7,9,11)]
for (col in missing_col) {
missing_ind <- rbernoulli(n,p = missing_prob)
df_observed[missing_ind, col] <- NA
}
df <- df %>% mutate_all(as.numeric)
class(df)
df$VEH
class(df$VEH)
matrix(df)
df <- df_observed %>% mutate_all(as.numeric)
df
# load dataset: df
load('../Datasets/ordinalPUMS.Rdata')
# take 10,000 samples: df
n = 10000
sample <- sample(nrow(df), size = 10000)
df <- df[sample,]
# create MCAR scneario with 30% chance of missing: df_observed
missing_prob = 0.3
df_observed <- df
missing_col = colnames(df)[c(1,3,5,7,9,11)]
for (col in missing_col) {
missing_ind <- rbernoulli(n,p = missing_prob)
df_observed[missing_ind, col] <- NA
}
source("../probitBayes.R")
Mon = 100
B = 10
thin.init = 5
# function(y, N = 40, Mon = 2000, B = 300, thin.int = 5, seed = 0)
sampled_y <- probitBayesImputation(df_observed, Mon, B, thin.init)
# DO NOT ALTER CODE IN THIS CHUNK
# The very first time you use this R markdown file, you should install each of the packages below.
# The same goes for other packages you might decide to use
# Remember that you only need to install each R package once in R (ever -- unless you change computers).
# All you need to do whenever you need to use the package again (after restarting the R session),
# is to use the library function to call the package.
# For example, type install.packages("knitr") in the console to install the knitr package.
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h', fig.align = 'center')
knitr::opts_chunk$set(fig.cap = "",  fig.path = "Plot")
library(knitr)
library(dplyr)
library(arm)
library(pROC)
library(tidyverse)
library(MASS)
library(tigerstats)
library(leaps)
library(car)
library(rms)
require(caret)
require(e1071)
library(lme4)
library(lattice)
library(broom)
library(boot)
library(ggplot2)
library(cobalt)
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
require(MCMCpack)
library(abind)
library(matrixStats)
library(truncnorm)
library(mvtnorm)
library(MCMCpack)
library(mnormt)
library(coda)
# load dataset: df
load('../Datasets/ordinalPUMS.Rdata')
# take 10,000 samples: df
n = 10000
sample <- sample(nrow(df), size = 10000)
df <- df[sample,]
# create MCAR scneario with 30% chance of missing: df_observed
missing_prob = 0.3
df_observed <- df
missing_col = colnames(df)[c(1,3,5,7,9,11)]
for (col in missing_col) {
missing_ind <- rbernoulli(n,p = missing_prob)
df_observed[missing_ind, col] <- NA
}
iter = 2000
# 1. Create and initialize the Rcpp_Lcm model object
model = CreateModel(X = df, MCZ = NULL, K = 40, Nmax = 0,
aalpha = 0.25, balpha = 0.25, seed = 0)
library(NPBayesImputeCat)
iter = 2000
# 1. Create and initialize the Rcpp_Lcm model object
model = CreateModel(X = df, MCZ = NULL, K = 40, Nmax = 0,
aalpha = 0.25, balpha = 0.25, seed = 0)
# 2. Set tracer
model$SetTrace(c('k_star', 'psi', 'ImputedX', 'alpha'),iter)
# 3. Run model
model$Run(300,iter,5)
# load dataset: df
load('../Datasets/ordinalPUMS.Rdata')
# take 10,000 samples: df
n = 10000
sample <- sample(nrow(df), size = 10000)
df <- df[sample,]
# create MCAR scneario with 30% chance of missing: df_observed
missing_prob = 0.3
df_observed <- df
missing_col = colnames(df)[c(1,3,5,7,9,11)]
for (col in missing_col) {
missing_ind <- rbernoulli(n,p = missing_prob)
df_observed[missing_ind, col] <- NA
}
N = 40
Mon = 2000
B = 300
thin.int = 5
# 1. Create and initialize the Rcpp_Lcm model object
model = CreateModel(X = df, MCZ = NULL, K = N, Nmax = 0,
aalpha = 0.25, balpha = 0.25, seed = 0)
# 2. Set tracer
model$SetTrace(c('k_star', 'psi', 'ImputedX', 'alpha'),iter)
# load dataset: df
load('../Datasets/ordinalPUMS.Rdata')
# take 10,000 samples: df
n = 10000
sample <- sample(nrow(df), size = 10000)
df <- df[sample,]
# create MCAR scneario with 30% chance of missing: df_observed
missing_prob = 0.3
df_observed <- df
missing_col = colnames(df)[c(1,3,5,7,9,11)]
for (col in missing_col) {
missing_ind <- rbernoulli(n,p = missing_prob)
df_observed[missing_ind, col] <- NA
}
N = 40
Mon = 2000
B = 300
thin.int = 5
# 1. Create and initialize the Rcpp_Lcm model object
model = CreateModel(X = df, MCZ = NULL, K = N, Nmax = 0,
aalpha = 0.25, balpha = 0.25, seed = 0)
# 2. Set tracer
model$SetTrace(c('k_star', 'psi', 'ImputedX', 'alpha'),Mon)
# 3. Run model using Run(burnin, iter, thinning)
model$Run(B,Mon,thin.int)
# Extract results
output <- model$GetTrace()
k_star <- output$k_star
psi <- output$psi
imputed_df <- output$ImputedX
alpha <- output$alpha
#retrieve parameters from the final iteration
result <- model$snapshot
#convert ImputedX matrix to dataframe, using proper factors/names etc.
ImputedX <- GetDataFrame(result$ImputedX,df)
dim(imputed_df)[2]
var_index = 1
table(imputed_df[,seq(var_index, dim(imputed_df)[2], dim(df)[2])])
table(df[,1])
dim(table(df[,1]))
concat
paste('as', 1)
# Original distribution without missing
var_index = 1
y_original = df[,var_index]
original_pmf = table(y_original)/length(y_original)
# Observed distribution
missing_indicator = is.na(df_observed)[,var_index]
y_observed = y_original[!missing_indicator, var_index]
missing_indicator
dim()
dim(missing_indicator)
length(missing_indicator)
# Original distribution without missing
var_index = 1
y_original = df[,var_index]
original_pmf = table(y_original)/length(y_original)
# Observed distribution
missing_indicator = is.na(df_observed)[,var_index]
y_observed = y_original[!missing_indicator]
observed_pmf = table(y_observed)/length(y_observed)
# Extract variable from imputed data
y_imputed = y
# Original distribution without missing
var_index = 1
y_original = df[,var_index]
original_pmf = table(y_original)/length(y_original)
# Observed distribution
missing_indicator = is.na(df_observed)[,var_index]
y_observed = y_original[!missing_indicator]
observed_pmf = table(y_observed)/length(y_observed)
# Extract variable from imputed data
imputed_pmf = table(imputed_df[,seq(var_index, dim(imputed_df)[2], dim(df)[2])])
imputed_pmf = imputed_pmf/sum(imputed_pmf)
results = rbind(original_pmf,observed_pmf,imputed_pmf)
colnames(results)<- 1:dim(imputed_pmf)
barplot(results, xlab = 'Category', beside = TRUE,
legend = TRUE, main = paste('Blocked Gibbs Sampling Assessment:', var_index),
ylim = c(0,0.5))
df
colnames(df)
# Original distribution without missing
var_index = 1
y_original = df[,var_index]
original_pmf = table(y_original)/length(y_original)
# Observed distribution
missing_indicator = is.na(df_observed)[,var_index]
y_observed = y_original[!missing_indicator]
observed_pmf = table(y_observed)/length(y_observed)
# Extract variable from imputed data
imputed_pmf = table(imputed_df[,seq(var_index, dim(imputed_df)[2], dim(df)[2])])
imputed_pmf = imputed_pmf/sum(imputed_pmf)
results = rbind(original_pmf,observed_pmf,imputed_pmf)
colnames(results)<- 1:dim(imputed_pmf)
barplot(results, xlab = 'Category', beside = TRUE,
legend = TRUE, main = paste('Blocked Gibbs Sampling Assessment:', colnames(df)[var_index]),
ylim = c(0,0.5))
# Original distribution without missing
var_index = 1
y_original = df[,var_index]
original_pmf = table(y_original)/length(y_original)
# Observed distribution
missing_indicator = is.na(df_observed)[,var_index]
y_observed = y_original[!missing_indicator]
observed_pmf = table(y_observed)/length(y_observed)
# Extract variable from imputed data
imputed_pmf = table(imputed_df[,seq(var_index, dim(imputed_df)[2], dim(df)[2])])
imputed_pmf = imputed_pmf/sum(imputed_pmf)
results = rbind(original_pmf,observed_pmf,imputed_pmf)
colnames(results)<- 1:dim(imputed_pmf)
barplot(results, xlab = 'Category', beside = TRUE,
legend = TRUE,
main = paste('Blocked Gibbs Sampling Assessment:', colnames(df)[var_index]))
# DO NOT ALTER CODE IN THIS CHUNK
# The very first time you use this R markdown file, you should install each of the packages below.
# The same goes for other packages you might decide to use
# Remember that you only need to install each R package once in R (ever -- unless you change computers).
# All you need to do whenever you need to use the package again (after restarting the R session),
# is to use the library function to call the package.
# For example, type install.packages("knitr") in the console to install the knitr package.
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h', fig.align = 'center')
knitr::opts_chunk$set(fig.cap = "",  fig.path = "Plot")
library(knitr)
library(dplyr)
library(arm)
library(pROC)
library(tidyverse)
library(MASS)
library(tigerstats)
library(leaps)
library(car)
library(rms)
require(caret)
require(e1071)
library(lme4)
library(lattice)
library(broom)
library(boot)
library(ggplot2)
library(cobalt)
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
require(MCMCpack)
library(abind)
library(matrixStats)
library(NPBayesImputeCat)
# Define mixing proportion
set.seed(0)
pi_true = c(0.3, 0.1, 0.6)
# Theta 1 for mixture cluster 1
theta_11_true = c(0.7,0.2,0.1)
theta_12_true = c(0.1,0.8,0.1)
theta_13_true =c(0.2,0.1,0.7)
# Theta 2 for mixture cluster 2
theta_21_true = c(0.05,0.75,0.2)
theta_22_true = c(0.2,0.15,0.65)
theta_23_true =c(0.7,0.2,0.1)
# Theta 3 for mixture cluster 3
theta_31_true = c(0.1,0.1,0.8)
theta_32_true = c(0.7,0.15,0.15)
theta_33_true =c(0.1,0.7,0.2)
# Theta row i is cluster i, column j is category j
theta_p1_true = rbind(theta_11_true, theta_21_true, theta_31_true)
theta_p2_true = rbind(theta_12_true, theta_22_true, theta_32_true)
theta_p3_true = rbind(theta_13_true, theta_23_true, theta_33_true)
# Create simulated data
n = 300
class_i = rmultinom(n, size = 1, prob = pi_true)
x1 = c()
x2 = c()
x3_original = c()
for (i in 1:n) {
x1 = cbind(x1, rmultinom(1, size = 1, prob = theta_p1_true[class_i[, i]==1,]))
x2 = cbind(x2, rmultinom(1, size = 1, prob = theta_p2_true[class_i[, i]==1,]))
x3_original = cbind(x3_original, rmultinom(1, size = 1, prob = theta_p3_true[class_i[, i]==1,]))
}
# Format data input
col1 = as.factor(apply(c(1,2,3)*x1, MARGIN = 2, FUN = sum))
col2 = as.factor(apply(c(1,2,3)*x2, MARGIN = 2, FUN = sum))
col3 = as.factor(apply(c(1,2,3)*x3_original, MARGIN = 2, FUN = sum))
df = data.frame(col1, col2, col3)
colnames(df)<- c('feature1', 'feature2', 'feature3')
df
# Define parameter of logistic function
w1 =  c(-0.75, -1, 0.2)
w2 = c(0.6, -2, 0.5)
w3 = c(0.2, -0.8, -0.4)
# Calculate probability of missingness of features 3
prob = apply(w1*x1, MARGIN = 2, FUN = sum) +
apply(w2*x2, MARGIN = 2, FUN = sum) +
apply(w3*x3_original, MARGIN = 2, FUN = sum)
prob = 1/(exp(-prob)+1)
# Indicator for X3miss
indicator = rbernoulli(n = 300, p = prob)
df[indicator, 3] = c(NA)
iter = 10000
# 1. Create and initialize the Rcpp_Lcm model object
model = CreateModel(X = df, MCZ = NULL, K = 10, Nmax = 0,
aalpha = 0.25, balpha = 0.25, seed = 0)
# 2. Set tracer
model$SetTrace(c('k_star', 'psi', 'ImputedX', 'alpha'),iter)
# 3. Run model
model$Run(5000,iter,1)
# Extract results
output <- model$GetTrace()
k_star <- output$k_star
psi <- output$psi
imputed_df <- output$ImputedX
alpha <- output$alpha
#retrieve parameters from the final iteration
result <- model$snapshot
#convert ImputedX matrix to dataframe, using proper factors/names etc.
ImputedX <- GetDataFrame(result$ImputedX,df)
table(imputed_df[,seq(3, dim(imputed_df)[2], 3)])
table(df[,3])
for (var_index in missing_col) {
y_original = df[,var_index]
original_pmf = table(y_original)/length(y_original)
# Observed distribution
missing_indicator = is.na(df_observed)[,var_index]
y_observed = y_original[!missing_indicator]
observed_pmf = table(y_observed)/length(y_observed)
# Extract variable from imputed data
imputed_pmf = table(imputed_df[,seq(var_index, dim(imputed_df)[2], dim(df)[2])])
imputed_pmf = imputed_pmf/sum(imputed_pmf)
results = rbind(original_pmf,observed_pmf,imputed_pmf)
colnames(results)<- 1:dim(imputed_pmf)
barplot(results, xlab = 'Category', beside = TRUE,
legend = TRUE,
main = paste('Blocked Gibbs Sampling Assessment:', colnames(df)[var_index]))
}
# load dataset: df
load('../Datasets/ordinalPUMS.Rdata')
# take 10,000 samples: df
n = 10000
sample <- sample(nrow(df), size = 10000)
df <- df[sample,]
# create MCAR scneario with 30% chance of missing: df_observed
missing_prob = 0.3
df_observed <- df
missing_col = colnames(df)[c(1,3,5,7,9,11)]
for (col in missing_col) {
missing_ind <- rbernoulli(n,p = missing_prob)
df_observed[missing_ind, col] <- NA
}
N = 40
Mon = 2000
B = 300
thin.int = 5
# 1. Create and initialize the Rcpp_Lcm model object
model = CreateModel(X = df, MCZ = NULL, K = N, Nmax = 0,
aalpha = 0.25, balpha = 0.25, seed = 0)
# 2. Set tracer
model$SetTrace(c('k_star', 'psi', 'ImputedX', 'alpha'),Mon)
# 3. Run model using Run(burnin, iter, thinning)
model$Run(B,Mon,thin.int)
# Extract results
output <- model$GetTrace()
k_star <- output$k_star
psi <- output$psi
imputed_df <- output$ImputedX
alpha <- output$alpha
#retrieve parameters from the final iteration
result <- model$snapshot
#convert ImputedX matrix to dataframe, using proper factors/names etc.
ImputedX <- GetDataFrame(result$ImputedX,df)
# Original distribution without missing
var_index = 1
y_original = df[,var_index]
original_pmf = table(y_original)/length(y_original)
# Observed distribution
missing_indicator = is.na(df_observed)[,var_index]
y_observed = y_original[!missing_indicator]
observed_pmf = table(y_observed)/length(y_observed)
# Extract variable from imputed data
imputed_pmf = table(imputed_df[,seq(var_index, dim(imputed_df)[2], dim(df)[2])])
imputed_pmf = imputed_pmf/sum(imputed_pmf)
results = rbind(original_pmf,observed_pmf,imputed_pmf)
colnames(results)<- 1:dim(imputed_pmf)
barplot(results, xlab = 'Category', beside = TRUE,
legend = TRUE,
main = paste('Blocked Gibbs Sampling Assessment:', colnames(df)[var_index]))
for (var_index in missing_col) {
y_original = df[,var_index]
original_pmf = table(y_original)/length(y_original)
# Observed distribution
missing_indicator = is.na(df_observed)[,var_index]
y_observed = y_original[!missing_indicator]
observed_pmf = table(y_observed)/length(y_observed)
# Extract variable from imputed data
imputed_pmf = table(imputed_df[,seq(var_index, dim(imputed_df)[2], dim(df)[2])])
imputed_pmf = imputed_pmf/sum(imputed_pmf)
results = rbind(original_pmf,observed_pmf,imputed_pmf)
colnames(results)<- 1:dim(imputed_pmf)
barplot(results, xlab = 'Category', beside = TRUE,
legend = TRUE,
main = paste('Blocked Gibbs Sampling Assessment:', colnames(df)[var_index]))
}
missing_col
for (var_index in c(1,3,5,7,9,11)) {
y_original = df[,var_index]
original_pmf = table(y_original)/length(y_original)
# Observed distribution
missing_indicator = is.na(df_observed)[,var_index]
y_observed = y_original[!missing_indicator]
observed_pmf = table(y_observed)/length(y_observed)
# Extract variable from imputed data
imputed_pmf = table(imputed_df[,seq(var_index, dim(imputed_df)[2], dim(df)[2])])
imputed_pmf = imputed_pmf/sum(imputed_pmf)
results = rbind(original_pmf,observed_pmf,imputed_pmf)
colnames(results)<- 1:dim(imputed_pmf)
barplot(results, xlab = 'Category', beside = TRUE,
legend = TRUE,
main = paste('Blocked Gibbs Sampling Assessment:', colnames(df)[var_index]))
}
# The number of clusters/latent groups used
plot(1:length(k_star), k_star, xlab = 'trials',
ylab = 'number of active clusters',
main = 'Number of clusters used over time', ylim = c(0,30))
# The number of clusters/latent groups used
plot(1:length(k_star), k_star, xlab = 'trials',
ylab = 'number of active clusters',
main = 'Number of clusters used over time', ylim = c(0,40))
# sampled alpha value for the stick breaking process
plot(1:length(alpha), alpha, xlab = 'trials',
ylab = 'alpha', type = 'l',
main = 'alpha value for the stick breaking process')
N = 40
Mon = 2000
B = 300
thin.int = 5
# 1. Create and initialize the Rcpp_Lcm model object
model = CreateModel(X = df, MCZ = NULL, K = N, Nmax = 0,
aalpha = 0.25, balpha = 0.25, seed = 0)
# 2. Set tracer
model$SetTrace(c('k_star', 'psi', 'ImputedX', 'alpha'),Mon)
# 3. Run model using Run(burnin, iter, thinning)
model$Run(B,Mon,thin.int)
