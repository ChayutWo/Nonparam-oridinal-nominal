library(pls)
pcr.fit <- pcr(Salary~., data = Hitters, scale = TRUE, validation = 'CV')
summary(pcr.fit)
validationplot(pcr.fit, val.type = 'MSEP')
set.seed(1)
pcr.fit<-pcr(Salary~., data = Hitters, subset = train, sclae = TRUE, validation = 'CV')
validationplot(pcr.fit, val.type = 'MSEP')
pcr.pred = predict(pcr.fit, x[test,], ncomp = 7)
mean((pcr.pred - y[test])^2)
mean((pcr.pred - y.test)^2)
pcr.fit<-pcr(Salary~., data = Hitters, scale = TRUE, ncomp = 7)
pcr.fit<-pcr(Salary~., data = Hitters, subset = train, scale = TRUE, validation = 'CV')
validationplot(pcr.fit, val.type = 'MSEP')
pcr.pred = predict(pcr.fit, x[test,], ncomp = 7)
mean((pcr.pred - y.test)^2)
pcr.fit<-pcr(Salary~., data = Hitters, scale = TRUE, ncomp = 7)
summary(pcr.fit)
set.seed(1)
pls.fit <- plsr(Salary~., data = Hitters, subset = train, scale = TRUE, validation = 'CV')
summary(pls.fit)
pls.pred <-predict(pls.fit, x[test,], ncomp = 2)
mean((pls.pred - y.test)^2)
install.packages('tree')
library(tree)
library(ISLR)
attach(Carseats)
High = ifelse(Sales<=8, 'No', 'Yes')
Carseats = data.frame(Carseats, High)
tree <- tree(High~.-Sales, data = Carseats)
summary(tree)
plot(tree)
text(tree, pretty = 0)
tree
set.seed(2)
train = sample(1:nrow(Carseats), 200)
Carseats.test = Carseats[-train,]
High.test = High[-train]
tree <- tree(High~.-Sales, data = Carseats, subset = train)
tree.pred = predict(tree, Carseats.test, type = 'Class')
tree.pred = predict(tree, Carseats.test, type = 'class')
table(tree.pred, High.test)
set.seed(3)
cv.car = cv.tree(tree, FUN = prune.misclass())
cv.car = cv.tree(tree, FUN = prune.misclass
cv.car = cv.tree(tree, FUN = prune.misclass)
cv.car = cv.tree(tree, FUN = prune.misclass)
names(cv.car)
cv.car
par(mfrow = c(1,2))
plot(cv.car$sizw, cv.car$dev, type = 'b')
plot(cv.car$size, cv.car$dev, type = 'b')
prune.car = prune.misclass(tree, best= 9)
plot(prune.car)
text(prune.car, pretty = 0)
tree.pred = predict(prune.car, Carseats.test, type = 'class')
table(tree.pred, High.test)
library(MASS)
set.seed(1)
train = sample(1:nrow(Boston), nrow(Boston)/2)
tree.boston = tree(medv~., Boston, subset = train)
summary(tree.boston)
cv.boston = cv.tree(tree.boston)
plot(cv.boston$size, cv.boston$dev)
library(randomForest)
set.seed(1)
bag.boston = randomForest(medv~., data = Boston, subset = train, mtry = 13, importance = TRUE)
bag.boston
yhat.bag = predict(bag.boston, newdata = Boston[-train,])
plot(yhat.bag, Boston[-train, 'medv'])
importance(bag.boston)
varImpPlot(bag.boston)
install.packages(gbm)
install.packages('gbm')
library(gbm)
set.seed(1)
boost.boston = gbm(medv~., data = Boston[train,], distribution = 'gaussian', n.trees = 5000, interaction.depth = 4)
summary(boost.boston)
plot(boost.boston, i= 'rm')
library(ISLR)
nci.labs = NCI60$labs
nci.data = NCI60$data
nci.labs[1:4]
pr.out = prcomp(nci.data, scale = TRUE)
pr.out = prcomp(nci.data, scale = TRUE)
Cols=function (vec){
cols=rainbow (length(unique(vec)))
return(cols[as.numeric (as.factor(vec))])
}
plot(pr.out$x[,1:2], col=Cols(nci.labs), pch=19,
xlab="Z1",ylab="Z2")
plot(pr.out)
par(mfrow=c(1,2))
plot(pr.out$x[,1:2], col=Cols(nci.labs), pch=19,
xlab="Z1",ylab="Z2")
plot(pr.out$x[,c(1,3)], col=Cols(nci.labs), pch=19,
xlab="Z1",ylab="Z3")
sd.data = scale(nci.data)
data.dist = dist(sd.data)
plot(hclust(data.dist, method = 'average'), lavels = nci.labs)
nci.labs
nci.labs
par(mfrow=c(1,1))
plot(hclust(data.dist, method = 'average'), lavels = nci.labs)
plot(hclust(data.dist, method = 'average'), labels = nci.labs)
hc.out = hclust(data.dist)
hc.cluster = cutree(hc.out, 4)
table(hc.cluster, nci.labs)
summary(hc.out)
set.seed(2)
km.out = kmeans(sd.data, 4, nstart = 20)
km.cluster = km.out$cluster
table(km.cluster, hc.cluster)
hc.out = hclust(dist(pr.out$x[,1:5]))
plot(hc.out, labels = nci.labs)
O <- 23.74/33.84
nonO <- (100-23.74)/(100-33.84)
O/nonO
nonO <- (100-25.74)/(100-33.84)
O <- 25.74/33.84
O/nonO
prob =c(0.3384, 1-0.3384)
chisq.test(x = c(486, 1888-486), p = prob)
chisq.test(x = c(486, 1888-486), p = prob)
prob =c(0.0910, 1-0.0910)
chisq.test(x = c(193, 1888-193), p = prob)
chisq.test(x = c(25.74, 33.84), p = prob)
prob =c(0.3216, 0.2490, 0.0910, 0.3384)
chisq.test(x = c(715, 494, 193, 486), p = prob)
17.88+0.983+1.72+37.852
chisq.test(x = c(85, 50, 19, 52), p = prob)
prob
prob2 = c(0.3775, 0.2642, 0.1003, 0.2580)
chisq.test(x = c(85, 50, 19, 52), p = prob2)
sigma<-1/(2*pi)
sigma
sigma<-sqrt(1/(2*pi))
load('../Datasets/ordinalPUMS.Rdata')
load('../ordinalPUMS.Rdata')
setwd("D:/DS_Project/Nonparam-oridinal-nominal")
load('../ordinalPUMS.Rdata')
load('..//ordinalPUMS.Rdata')
load('..\\ordinalPUMS.Rdata')
load('..\ordinalPUMS.Rdata')
load('../ordinalPUMS.Rdata')
load('ordinalPUMS.Rdata')
source("probitBayes.R")
install.packages('knitr')
install.packages('dplyr')
install.packages('arm')
install.packages('pROC')
install.packages('tidyverse')
install.packages('lme4')
install.packages('lattice')
install.[a]
install.packages('broom')
install.packages('boot')
install.packages('rstanarm')
install.packages('magrittr')
install.packages('rstan')
install.packages('MCMCpack')
install.packages('abind')
install.packages('matrixStats')
install.packages('truncnorm')
install.packages('mvtnorm')
install.packages('mnormt')
install.packages('coda')
# DO NOT ALTER CODE IN THIS CHUNK
# The very first time you use this R markdown file, you should install each of the packages below.
# The same goes for other packages you might decide to use
# Remember that you only need to install each R package once in R (ever -- unless you change computers).
# All you need to do whenever you need to use the package again (after restarting the R session),
# is to use the library function to call the package.
# For example, type install.packages("knitr") in the console to install the knitr package.
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h', fig.align = 'center')
knitr::opts_chunk$set(fig.cap = "",  fig.path = "Plot")
library(knitr)
library(dplyr)
library(arm)
library(pROC)
library(tidyverse)
library(MASS)
library(tigerstats)
library(leaps)
library(car)
library(rms)
require(caret)
require(e1071)
library(lme4)
library(lattice)
library(broom)
library(boot)
library(ggplot2)
library(cobalt)
require(rstanarm)
require(magrittr)
require(rstan)
require(MCMCpack)
library(abind)
library(matrixStats)
library(truncnorm)
library(mvtnorm)
library(mnormt)
library(coda)
# load dataset: df
load('ordinalPUMS.Rdata')
setwd("D:/DS_Project/Nonparam-oridinal-nominal")
# load dataset: df
load('ordinalPUMS.Rdata')
load('ordinalPUMS.Rdata')
# load dataset: df
load('.//ordinalPUMS.Rdata')
# load dataset: df
load('./ordinalPUMS.Rdata')
# load dataset: df
load('../ordinalPUMS.Rdata')
# take 10,000 samples: df
n = 10000
sample <- sample(nrow(df), size = 10000)
df <- df[sample,]
# create MCAR scneario with 30% chance of missing: df_observed
missing_prob = 0.3
df_observed <- df
missing_col = colnames(df)[c(1,3,5,7,9,11)]
for (col in missing_col) {
missing_ind <- rbernoulli(n,p = missing_prob)
df_observed[missing_ind, col] <- NA
}
# load dataset: df
load('../ordinalPUMS.Rdata')
# take 10,000 samples: df
n = 10000
sample <- sample(nrow(df), size = 10000)
df <- df[sample,]
# create MCAR scneario with 30% chance of missing: df_observed
missing_prob = 0.3
df_observed <- df
missing_col = colnames(df)[c(1,3,5,7,9,11)]
for (col in missing_col) {
missing_ind <- rbernoulli(n,p = missing_prob)
df_observed[missing_ind, col] <- NA
}
# load dataset: df
load('../ordinalPUMS.Rdata')
# take 10,000 samples: df
n = 10000
sample <- sample(nrow(df), size = 10000)
df <- df[sample,]
# create MCAR scneario with 30% chance of missing: df_observed
set.seed(0)
missing_prob = 0.3
df_observed <- df
missing_col = colnames(df)[c(1,3,5,7,9,11)]
for (col in missing_col) {
missing_ind <- rbernoulli(n,p = missing_prob)
df_observed[missing_ind, col] <- NA
}
source("probitBayes.R")
source("../probitBayes.R")
N = 40
Mon = 100
B = 5
thin.int = 2
# function(y, N = 40, Mon = 2000, B = 300, thin.int = 5, seed = 0)
sampled_y <- probitBayesImputation(df_observed, N, Mon, B, thin.int)
View(df)
# DO NOT ALTER CODE IN THIS CHUNK
# The very first time you use this R markdown file, you should install each of the packages below.
# The same goes for other packages you might decide to use
# Remember that you only need to install each R package once in R (ever -- unless you change computers).
# All you need to do whenever you need to use the package again (after restarting the R session),
# is to use the library function to call the package.
# For example, type install.packages("knitr") in the console to install the knitr package.
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h', fig.align = 'center')
knitr::opts_chunk$set(fig.cap = "",  fig.path = "Plot")
library(knitr)
library(dplyr)
library(arm)
library(pROC)
library(tidyverse)
library(MASS)
library(tigerstats)
library(leaps)
library(car)
library(rms)
require(caret)
require(e1071)
library(lme4)
library(lattice)
library(broom)
library(boot)
library(ggplot2)
library(cobalt)
require(rstanarm)
require(magrittr)
require(rstan)
require(MCMCpack)
library(abind)
library(matrixStats)
library(truncnorm)
library(mvtnorm)
library(mnormt)
library(coda)
# sample MCAR dataset from PUMS
source("../../utils/sampleMCAR.R")
n = 10000
missing_col = c(1,3,7,9,10,11)
missing_prob = 0.3
set.seed(0)
output_list <- sampleMCAR(n, missing_prob)
df <- output_list[['df']]
df_observed <- output_list[['df_observed']]
source("../../probitBayes_optimized.R")
N = 40
Mon = 300
B = 1
thin.int = 1
# function(y, N = 40, Mon = 2000, B = 300, thin.int = 5, seed = 0)
output_list <- probitBayesImputation(df_observed, N, Mon, B, thin.int)
proc.time()
ptm <- proc.time()
proc.time()
proc.time()
source("../../probitBayes_optimized.R")
N = 40
Mon = 20
B = 1
thin.int = 1
ptm <- proc.time()
# function(y, N = 40, Mon = 2000, B = 300, thin.int = 5, seed = 0)
output_list <- probitBayesImputation(df_observed, N, Mon, B, thin.int)
proc.time() - ptm
source("../../probitBayes.R")
N = 40
Mon = 20
B = 1
thin.int = 1
ptm <- proc.time()
# function(y, N = 40, Mon = 2000, B = 300, thin.int = 5, seed = 0)
output_list <- probitBayesImputation(df_observed, N, Mon, B, thin.int)
proc.time() - ptm
Sys.time()
start = Sys.time()
Sys.time()-start
# sample MCAR dataset from PUMS
source("../../utils/sampleMCAR.R")
n = 10000
missing_col = c(1,3,7,9,10,11)
missing_prob = 0.3
set.seed(0)
output_list <- sampleMCAR(n, missing_prob)
df <- output_list[['df']]
df_observed <- output_list[['df_observed']]
source("../../probitBayes.R")
N = 40
Mon = 20
B = 1
thin.int = 1
start = Sys.time()
# function(y, N = 40, Mon = 2000, B = 300, thin.int = 5, seed = 0)
output_list <- probitBayesImputation(df_observed, N, Mon, B, thin.int)
Sys.time() - start
source("../../probitBayes_optimized.R")
N = 40
Mon = 20
B = 1
thin.int = 1
start = Sys.time()
# function(y, N = 40, Mon = 2000, B = 300, thin.int = 5, seed = 0)
output_list <- probitBayesImputation(df_observed, N, Mon, B, thin.int)
Sys.time() - start
source("../../probitBayes_optimized.R")
N = 40
Mon = 500
B = 1
thin.int = 1
start = Sys.time()
# function(y, N = 40, Mon = 2000, B = 300, thin.int = 5, seed = 0)
output_list <- probitBayesImputation(df_observed, N, Mon, B, thin.int)
Sys.time() - start
# sample MCAR dataset from PUMS
source("../../utils/sampleMCAR.R")
n = 10000
missing_col = c(1,3,7,9,10,11)
missing_prob = 0.3
set.seed(0)
output_list <- sampleMCAR(n, missing_prob)
df <- output_list[['df']]
df_observed <- output_list[['df_observed']]
source("../../probitBayes_optimized.R")
N = 40
Mon = 500
B = 1
thin.int = 1
start = Sys.time()
# function(y, N = 40, Mon = 2000, B = 300, thin.int = 5, seed = 0)
output_list <- probitBayesImputation(df_observed, N, Mon, B, thin.int)
Sys.time() - start
# sample MCAR dataset from PUMS
source("../../utils/sampleMCAR.R")
n = 10000
missing_col = c(1,3,7,9,10,11)
missing_prob = 0.3
set.seed(0)
output_list <- sampleMCAR(n, missing_prob)
df <- output_list[['df']]
df_observed <- output_list[['df_observed']]
source("../../probitBayes.R")
N = 40
Mon = 500
B = 1
thin.int = 1
start = Sys.time()
# function(y, N = 40, Mon = 2000, B = 300, thin.int = 5, seed = 0)
output_list <- probitBayesImputation(df_observed, N, Mon, B, thin.int)
Sys.time() - start
# sample MCAR dataset from PUMS
source("../../utils/sampleMCAR.R")
n = 10000
missing_col = c(1,3,7,9,10,11)
missing_prob = 0.3
set.seed(0)
output_list <- sampleMCAR(n, missing_prob)
df <- output_list[['df']]
df_observed <- output_list[['df_observed']]
source("../../probitBayes_optimized.R")
N = 40
Mon = 500
B = 1
thin.int = 1
start = Sys.time()
# function(y, N = 40, Mon = 2000, B = 300, thin.int = 5, seed = 0)
output_list <- probitBayesImputation(df_observed, N, Mon, B, thin.int)
Sys.time() - start
Sys.time()
start = Sys.time()
class(Sys.time() - start)
Sys.time() - start
c(Sys.time() - start, Sys.time() - start, Sys.time() - start)
mean(c(Sys.time() - start, Sys.time() - start, Sys.time() - start))
start
diff_time = Sys.time() - start
diff_time
diff_time
diff_time
diff_time
diff_time
diff_time
diff_time = Sys.time() - start
diff_time
source("../../probitBayes_time.R")
N = 40
Mon = 10
B = 1
thin.int = 1
start = Sys.time()
# function(y, N = 40, Mon = 2000, B = 300, thin.int = 5, seed = 0)
output_list <- probitBayesImputation(df_observed, N, Mon, B, thin.int)
Sys.time() - start
source("../../probitBayes_time.R")
N = 40
Mon = 1
B = 1
thin.int = 1
start = Sys.time()
# function(y, N = 40, Mon = 2000, B = 300, thin.int = 5, seed = 0)
output_list <- probitBayesImputation(df_observed, N, Mon, B, thin.int)
Sys.time() - start
source("../../probitBayes_time.R")
N = 40
Mon = 100
B = 1
thin.int = 1
start = Sys.time()
# function(y, N = 40, Mon = 2000, B = 300, thin.int = 5, seed = 0)
output_list <- probitBayesImputation(df_observed, N, Mon, B, thin.int)
Sys.time() - start
source("../../probitBayes_time.R")
N = 40
Mon = 5
B = 1
thin.int = 1
start = Sys.time()
# function(y, N = 40, Mon = 2000, B = 300, thin.int = 5, seed = 0)
output_list <- probitBayesImputation(df_observed, N, Mon, B, thin.int)
Sys.time() - start
source("../../probitBayes_time.R")
N = 40
Mon = 5
B = 1
thin.int = 1
start = Sys.time()
# function(y, N = 40, Mon = 2000, B = 300, thin.int = 5, seed = 0)
output_list <- probitBayesImputation(df_observed, N, Mon, B, thin.int)
Sys.time() - start
source("../../probitBayes_time.R")
N = 40
Mon = 5
B = 1
thin.int = 1
start = Sys.time()
# function(y, N = 40, Mon = 2000, B = 300, thin.int = 5, seed = 0)
output_list <- probitBayesImputation(df_observed, N, Mon, B, thin.int)
Sys.time() - start
source("../../probitBayes_time.R")
N = 40
Mon = 5
B = 1
thin.int = 1
start = Sys.time()
# function(y, N = 40, Mon = 2000, B = 300, thin.int = 5, seed = 0)
output_list <- probitBayesImputation(df_observed, N, Mon, B, thin.int)
Sys.time() - start
