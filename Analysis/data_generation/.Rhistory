# Calculate true contingency probability
dummy = c(table(df[, variables]))
dummy = dummy/sum(dummy)
true_cont_table = c(true_cont_table, dummy)
}
}
root = paste('../../Results/',model_name,'/', missing_data_name, sep = '')
dof_name = paste(root,'_dof_',n_way,'way.csv', sep = '')
q_bar_name = paste(root,'_q_bar_',n_way,'way.csv', sep = '')
u_bar_name = paste(root,'_u_bar_',n_way,'way.csv', sep = '')
b_name = paste(root,'_b_',n_way,'way.csv', sep = '')
# load in data
dof = as.array(read_csv(dof_name)[[1]])
mean_estimate = as.array(read_csv(q_bar_name)[[1]])
within_group_var = as.array(read_csv(u_bar_name)[[1]])
across_group_var = as.array(read_csv(b_name)[[1]])
total_var = (1+1/n_imputations)*across_group_var + within_group_var
total_sd = sqrt(total_var)
# Calculate quantile for 95% confidence interval from t distribution
q_alpha = qt(0.975, df = dof)
# Calculate upper and lower bound of 95% confidence interval
upper_bound = mean_estimate+q_alpha*total_sd
lower_bound = mean_estimate-q_alpha*total_sd
coverage = c(lower_bound<=true_cont_table & true_cont_table<=upper_bound)
mean(coverage[!is.na(coverage)])
# DO NOT ALTER CODE IN THIS CHUNK
# The very first time you use this R markdown file, you should install each of the packages below.
# The same goes for other packages you might decide to use
# Remember that you only need to install each R package once in R (ever -- unless you change computers).
# All you need to do whenever you need to use the package again (after restarting the R session),
# is to use the library function to call the package.
# For example, type install.packages("knitr") in the console to install the knitr package.
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h', fig.align = 'center')
knitr::opts_chunk$set(fig.cap = "",  fig.path = "Plot")
library(knitr)
library(dplyr)
library(arm)
library(pROC)
library(tidyverse)
library(MASS)
library(tigerstats)
library(leaps)
library(car)
library(rms)
require(caret)
require(e1071)
library(lme4)
library(lattice)
library(broom)
library(boot)
library(ggplot2)
library(cobalt)
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
require(MCMCpack)
library(abind)
library(matrixStats)
library(truncnorm)
library(mvtnorm)
library(MCMCpack)
library(mnormt)
library(coda)
# sample MCAR dataset from PUMS
source("../../utils/sampleMCAR.R")
n = 10000
missing_col = c(1,3,7,9,10,11)
missing_prob = 0.3
set.seed(0)
output_list <- sampleMCAR(n, missing_prob)
df <- output_list[['df']]
df_observed <- output_list[['df_observed']]
library(mice)
imputed_df <-  mice(df_observed,m=10,print=F)
imputation_list = list()
for (i in 1:5) {
imputation_list[[i]] = complete(imputed_df, i)
}
# Code to be called on batch mode:
# R CMD BATCH '--args 1' run_batch.R
# the argument is the index for the dataset
library(tidyverse)
# clear workspace and load data
args <- commandArgs(TRUE)
print(args)
repindex <- as.numeric(args[1])
print(repindex)
source('../../utils/models/run_all_models.R')
# define the dataset name
root_fully_observed = 'fully_observed/fully_observed_'
root_MCAR_30 = 'MCAR_30/MCAR_30_'
root_MCAR_45 = 'MCAR_45/MCAR_45_'
root_MAR_30 = 'MAR_30/MAR_30_'
root_MAR_45 = 'MAR_45/MAR_45_'
# define simulation hyper parameter
n_imputations = 5
max_nway = 4
if (repindex <= 100) {
# repindex 1 - 100: MCAR_30 dataset
i = repindex
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MCAR_30, i, sep = '')
}else if (repindex <= 200) {
# repindex 101-200: MCAR_45 dataset
i = repindex - 100
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MCAR_45, i, sep = '')
}else if (repindex <= 300) {
# repindex 201-300: MAR_30 dataset
i = repindex - 200
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MAR_30, i, sep = '')
}else if (repindex <= 400) {
# repindex 301-400: MAR_45 dataset
i = repindex - 300
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MAR_45, i, sep = '')
}
print(paste('>> start running:', data_name, missing_data_name))
run_all_models(data_name, missing_data_name, n_imputations, max_nway)
# import function
library(tidyverse)
# sample MCAR dataset from PUMS
source("../../utils/sampleMCAR.R")
n = 10000
missing_col = c(1,3,7,9,10,11)
missing_prob = 0.3
set.seed(0)
dummy <- sampleMCAR(n, missing_prob)
source('../../utils/models/run_all_models.R')
# define the dataset name
root_fully_observed = 'fully_observed/fully_observed_'
root_MCAR_30 = 'MCAR_30/MCAR_30_'
root_MCAR_45 = 'MCAR_45/MCAR_45_'
root_MAR_30 = 'MAR_30/MAR_30_'
root_MAR_45 = 'MAR_45/MAR_45_'
# define simulation hyper parameter
n_imputations = 5
max_nway = 4
for (repindex in 1:2) {
if (repindex <= 100) {
# repindex 1 - 100: MCAR_30 dataset
i = repindex
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MCAR_30, i, sep = '')
}else if (repindex <= 200) {
# repindex 101-200: MCAR_45 dataset
i = repindex - 100
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MCAR_45, i, sep = '')
}else if (repindex <= 300) {
# repindex 201-300: MAR_30 dataset
i = repindex - 200
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MAR_30, i, sep = '')
}else if (repindex <= 400) {
# repindex 301-400: MAR_45 dataset
i = repindex - 300
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MAR_45, i, sep = '')
}
print(paste('>> start running:', data_name, missing_data_name))
run_all_models(data_name, missing_data_name, n_imputations, max_nway)
}
missing_data_name = "MCAR_30/MCAR_30_1"
model_name = 'MICE' # model to be tested
n_way = 2 # n_way to be tested
# calculate ground truth joint pmf
load('../../Datasets/ordinalPUMS.Rdata')
missing_col = c(1,3,7,9,10,11)
combinations = combn(1:11, n_way)
true_cont_table = c()
for (i in 1:(dim(combinations)[2])) {
variables = combinations[, i]
if (any(missing_col %in% variables)) {
# Calculate true contingency probability
dummy = c(table(df[, variables]))
dummy = dummy/sum(dummy)
true_cont_table = c(true_cont_table, dummy)
}
}
root = paste('../../Results/',model_name,'/', missing_data_name, sep = '')
dof_name = paste(root,'_dof_',n_way,'way.csv', sep = '')
q_bar_name = paste(root,'_q_bar_',n_way,'way.csv', sep = '')
u_bar_name = paste(root,'_u_bar_',n_way,'way.csv', sep = '')
b_name = paste(root,'_b_',n_way,'way.csv', sep = '')
# load in data
dof = as.array(read_csv(dof_name)[[1]])
mean_estimate = as.array(read_csv(q_bar_name)[[1]])
within_group_var = as.array(read_csv(u_bar_name)[[1]])
across_group_var = as.array(read_csv(b_name)[[1]])
total_var = (1+1/n_imputations)*across_group_var + within_group_var
total_sd = sqrt(total_var)
# Calculate quantile for 95% confidence interval from t distribution
q_alpha = qt(0.975, df = dof)
# Calculate upper and lower bound of 95% confidence interval
upper_bound = mean_estimate+q_alpha*total_sd
lower_bound = mean_estimate-q_alpha*total_sd
coverage = c(lower_bound<=true_cont_table & true_cont_table<=upper_bound)
mean(coverage[!is.na(coverage)])
missing_data_name = "MCAR_30/MCAR_30_1"
model_name = 'MICE' # model to be tested
n_way = 3 # n_way to be tested
# calculate ground truth joint pmf
load('../../Datasets/ordinalPUMS.Rdata')
missing_col = c(1,3,7,9,10,11)
combinations = combn(1:11, n_way)
true_cont_table = c()
for (i in 1:(dim(combinations)[2])) {
variables = combinations[, i]
if (any(missing_col %in% variables)) {
# Calculate true contingency probability
dummy = c(table(df[, variables]))
dummy = dummy/sum(dummy)
true_cont_table = c(true_cont_table, dummy)
}
}
root = paste('../../Results/',model_name,'/', missing_data_name, sep = '')
dof_name = paste(root,'_dof_',n_way,'way.csv', sep = '')
q_bar_name = paste(root,'_q_bar_',n_way,'way.csv', sep = '')
u_bar_name = paste(root,'_u_bar_',n_way,'way.csv', sep = '')
b_name = paste(root,'_b_',n_way,'way.csv', sep = '')
# load in data
dof = as.array(read_csv(dof_name)[[1]])
mean_estimate = as.array(read_csv(q_bar_name)[[1]])
within_group_var = as.array(read_csv(u_bar_name)[[1]])
across_group_var = as.array(read_csv(b_name)[[1]])
total_var = (1+1/n_imputations)*across_group_var + within_group_var
total_sd = sqrt(total_var)
# Calculate quantile for 95% confidence interval from t distribution
q_alpha = qt(0.975, df = dof)
# Calculate upper and lower bound of 95% confidence interval
upper_bound = mean_estimate+q_alpha*total_sd
lower_bound = mean_estimate-q_alpha*total_sd
coverage = c(lower_bound<=true_cont_table & true_cont_table<=upper_bound)
mean(coverage[!is.na(coverage)])
missing_data_name = "MCAR_30/MCAR_30_1"
model_name = 'MICE' # model to be tested
n_way = 1 # n_way to be tested
# calculate ground truth joint pmf
load('../../Datasets/ordinalPUMS.Rdata')
missing_col = c(1,3,7,9,10,11)
combinations = combn(1:11, n_way)
true_cont_table = c()
for (i in 1:(dim(combinations)[2])) {
variables = combinations[, i]
if (any(missing_col %in% variables)) {
# Calculate true contingency probability
dummy = c(table(df[, variables]))
dummy = dummy/sum(dummy)
true_cont_table = c(true_cont_table, dummy)
}
}
root = paste('../../Results/',model_name,'/', missing_data_name, sep = '')
dof_name = paste(root,'_dof_',n_way,'way.csv', sep = '')
q_bar_name = paste(root,'_q_bar_',n_way,'way.csv', sep = '')
u_bar_name = paste(root,'_u_bar_',n_way,'way.csv', sep = '')
b_name = paste(root,'_b_',n_way,'way.csv', sep = '')
# load in data
dof = as.array(read_csv(dof_name)[[1]])
mean_estimate = as.array(read_csv(q_bar_name)[[1]])
within_group_var = as.array(read_csv(u_bar_name)[[1]])
across_group_var = as.array(read_csv(b_name)[[1]])
total_var = (1+1/n_imputations)*across_group_var + within_group_var
total_sd = sqrt(total_var)
# Calculate quantile for 95% confidence interval from t distribution
q_alpha = qt(0.975, df = dof)
# Calculate upper and lower bound of 95% confidence interval
upper_bound = mean_estimate+q_alpha*total_sd
lower_bound = mean_estimate-q_alpha*total_sd
coverage = c(lower_bound<=true_cont_table & true_cont_table<=upper_bound)
mean(coverage[!is.na(coverage)])
# This code generate 100 subsample of the PUMS original data each with 10000 observations
# It then made each of those 100 dataset missing according to 4 missing mechanism
library(MASS)
library(tidyverse)
setwd("~/DS_Projects/Nonparam-oridinal-nominal/Analysis/data_generation")
source("../../utils/sample_PUMS.R")
source("../../utils/make_MCAR.R")
source("../../utils/make_MAR_30.R")
source("../../utils/make_MAR_45.R")
# Specify parameters of the dataset and missing data mechanism
n <- 10000
missing_col <- c(1,3,7,9,10,11)
set.seed(0)
# Root for different dataset
root_fully_observed <- '../../Datasets/fully_observed/fully_observed_'
root_MCAR_30 <- '../../Datasets/MCAR_30/MCAR_30_'
root_MCAR_45 <- '../../Datasets/MCAR_45/MCAR_45_'
root_MAR_30 <- '../../Datasets/MAR_30/MAR_30_'
root_MAR_45 <- '../../Datasets/MAR_45/MAR_45_'
for (i in 1:100) {
# Generate a full set of fully observed and missing dataframes
df <- sample_PUMS(n)
df_MCAR_30 <- make_MCAR(df, 0.3)
df_MCAR_45 <- make_MCAR(df, 0.45)
df_MAR_30 <- make_MAR_30(df)
df_MAR_45 <- make_MAR_45(df)
# Obtain a full path for the file to be saved
name_fully_observed <- paste(root_fully_observed, i,'.csv', sep = '')
name_MCAR_30 <- paste(root_MCAR_30, i,'.csv', sep = '')
name_MCAR_45 <- paste(root_MCAR_45, i,'.csv', sep = '')
name_MAR_30 <- paste(root_MAR_30, i,'.csv', sep = '')
name_MAR_45 <- paste(root_MAR_45, i,'.csv', sep = '')
# Save them according to the name and file structure
write.table(df, name_fully_observed, row.names = FALSE, sep = ',')
write.table(df_MCAR_30, name_MCAR_30, row.names = FALSE, sep = ',')
write.table(df_MCAR_45, name_MCAR_45, row.names = FALSE, sep = ',')
write.table(df_MAR_30, name_MAR_30, row.names = FALSE, sep = ',')
write.table(df_MAR_45, name_MAR_45, row.names = FALSE, sep = ',')
cat(paste('finish generating',i,'datasets','\n'))
}
View(df)
View(df_MAR_30)
apply(is.na(df), MARGIN = 2, mean)
apply(is.na(df_MCAR_30), MARGIN = 2, mean)
apply(is.na(df_MCAR_45), MARGIN = 2, mean)
apply(is.na(df_MAR_30), MARGIN = 2, mean)
apply(is.na(df_MAR_45), MARGIN = 2, mean)
View(df_MAR_45)
View(df_MCAR_30)
View(df_MCAR_45)
any(c(1,2,3,4)>5)
# DO NOT ALTER CODE IN THIS CHUNK
# The very first time you use this R markdown file, you should install each of the packages below.
# The same goes for other packages you might decide to use
# Remember that you only need to install each R package once in R (ever -- unless you change computers).
# All you need to do whenever you need to use the package again (after restarting the R session),
# is to use the library function to call the package.
# For example, type install.packages("knitr") in the console to install the knitr package.
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h', fig.align = 'center')
knitr::opts_chunk$set(fig.cap = "",  fig.path = "Plot")
library(knitr)
library(dplyr)
library(arm)
library(pROC)
library(tidyverse)
library(MASS)
library(tigerstats)
library(leaps)
library(car)
library(rms)
require(caret)
require(e1071)
library(lme4)
library(lattice)
library(broom)
library(boot)
library(ggplot2)
library(cobalt)
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
require(MCMCpack)
library(abind)
library(matrixStats)
library(truncnorm)
library(mvtnorm)
library(MCMCpack)
library(mnormt)
library(coda)
library(mice)
# Root for different dataset
root_fully_observed <- 'fully_observed/fully_observed_'
root_MCAR_30 <- 'MCAR_30/MCAR_30_'
root_MCAR_45 <- 'MCAR_45/MCAR_45_'
root_MAR_30 <- 'MAR_30/MAR_30_'
root_MAR_45 <- 'MAR_45/MAR_45_'
source('../../utils/load_data.R')
miss_df = c()
miss_MCAR_30 = c()
miss_MCAR_45 = c()
miss_MAR_30 = c()
miss_MAR_45 = c()
for (i in 1:100) {
# Obtain a full path for the file to be saved
name_fully_observed <- paste(root_fully_observed, i, sep = '')
name_MCAR_30 <- paste(root_MCAR_30, i, sep = '')
name_MCAR_45 <- paste(root_MCAR_45, i, sep = '')
name_MAR_30 <- paste(root_MAR_30, i, sep = '')
name_MAR_45 <- paste(root_MAR_45, i, sep = '')
# load data
df = load_data(name_fully_observed)
MCAR_30 <- load_data(name_MCAR_30)
MCAR_45 <- load_data(name_MCAR_45)
MAR_30 <- load_data(name_MAR_30)
MAR_45 <- load_data(name_MAR_45)
# compute missing probability
miss_df = rbind(miss_df, apply(is.na(df), MARGIN = 2, mean))
miss_MCAR_30 = rbind(miss_MCAR_30, apply(is.na(MCAR_30), MARGIN = 2, mean))
miss_MCAR_45 = rbind(miss_MCAR_45, apply(is.na(MCAR_45), MARGIN = 2, mean))
miss_MAR_30 = rbind(miss_MAR_30, apply(is.na(MAR_30), MARGIN = 2, mean))
miss_MAR_45 = rbind(miss_MAR_45,apply(is.na(MAR_45), MARGIN = 2, mean))
}
# Root for different dataset
root_fully_observed <- 'fully_observed/fully_observed_'
root_MCAR_30 <- 'MCAR_30/MCAR_30_'
root_MCAR_45 <- 'MCAR_45/MCAR_45_'
root_MAR_30 <- 'MAR_30/MAR_30_'
root_MAR_45 <- 'MAR_45/MAR_45_'
source('../../utils/load_data.R')
miss_df = c()
miss_MCAR_30 = c()
miss_MCAR_45 = c()
miss_MAR_30 = c()
miss_MAR_45 = c()
for (i in 1:100) {
# Obtain a full path for the file to be saved
name_fully_observed <- paste(root_fully_observed, i, sep = '')
name_MCAR_30 <- paste(root_MCAR_30, i, sep = '')
name_MCAR_45 <- paste(root_MCAR_45, i, sep = '')
name_MAR_30 <- paste(root_MAR_30, i, sep = '')
name_MAR_45 <- paste(root_MAR_45, i, sep = '')
# load data
df = load_data(name_fully_observed)
MCAR_30 <- load_data(name_MCAR_30)
MCAR_45 <- load_data(name_MCAR_45)
MAR_30 <- load_data(name_MAR_30)
MAR_45 <- load_data(name_MAR_45)
# compute missing probability
miss_df = rbind(miss_df, apply(is.na(df), MARGIN = 2, mean))
miss_MCAR_30 = rbind(miss_MCAR_30, apply(is.na(MCAR_30), MARGIN = 2, mean))
miss_MCAR_45 = rbind(miss_MCAR_45, apply(is.na(MCAR_45), MARGIN = 2, mean))
miss_MAR_30 = rbind(miss_MAR_30, apply(is.na(MAR_30), MARGIN = 2, mean))
miss_MAR_45 = rbind(miss_MAR_45,apply(is.na(MAR_45), MARGIN = 2, mean))
print(paste('>> finish computing:',i))
}
dim(miss_MAR_30)
# minimum
apply(miss_df, MARGIN = 2, min)
apply(miss_MCAR_30, MARGIN = 2, min)
apply(miss_MCAR_45, MARGIN = 2, min)
apply(miss_MAR_30, MARGIN = 2, min)
apply(miss_MAR_45, MARGIN = 2, min)
# maximum
apply(miss_df, MARGIN = 2, max)
apply(miss_MCAR_30, MARGIN = 2, max)
apply(miss_MCAR_45, MARGIN = 2, max)
apply(miss_MAR_30, MARGIN = 2, max)
apply(miss_MAR_45, MARGIN = 2, max)
# mean
apply(miss_df, MARGIN = 2, mean)
apply(miss_MCAR_30, MARGIN = 2, mean)
apply(miss_MCAR_45, MARGIN = 2, mean)
apply(miss_MAR_30, MARGIN = 2, mean)
apply(miss_MAR_45, MARGIN = 2, mean)
# mean
apply(miss_df, MARGIN = 2, mean)
apply(miss_MCAR_30, MARGIN = 2, mean)
apply(miss_MCAR_45, MARGIN = 2, mean)
apply(miss_MAR_30, MARGIN = 2, mean)
apply(miss_MAR_45, MARGIN = 2, mean)
# no missing value
boxplot(miss_df)
boxplot(miss_MCAR_30)
boxplot(miss_MCAR_45)
boxplot(miss_MAR_30)
boxplot(miss_MAR_45)
# overall mean
missing_col = c(1,3,7,9,10,11)
mean(miss_MCAR_30[,missing_col])
# overall mean
missing_col = c(1,3,7,9,10,11)
mean(miss_MCAR_30[,missing_col])
mean(miss_MCAR_45[,missing_col])
mean(miss_MAR_30[,missing_col])
mean(miss_MAR_45[,missing_col])
i = 1
# Obtain a full path for the file to be saved
name_fully_observed <- paste(root_fully_observed, i, sep = '')
name_MCAR_30 <- paste(root_MCAR_30, i, sep = '')
name_MCAR_45 <- paste(root_MCAR_45, i, sep = '')
name_MAR_30 <- paste(root_MAR_30, i, sep = '')
name_MAR_45 <- paste(root_MAR_45, i, sep = '')
# load data
df_1 = load_data(name_fully_observed)
MCAR_30_1 <- load_data(name_MCAR_30)
MCAR_45_1 <- load_data(name_MCAR_45)
MAR_30_1 <- load_data(name_MAR_30)
MAR_45_1 <- load_data(name_MAR_45)
i = 2
# Obtain a full path for the file to be saved
name_fully_observed <- paste(root_fully_observed, i, sep = '')
name_MCAR_30 <- paste(root_MCAR_30, i, sep = '')
name_MCAR_45 <- paste(root_MCAR_45, i, sep = '')
name_MAR_30 <- paste(root_MAR_30, i, sep = '')
name_MAR_45 <- paste(root_MAR_45, i, sep = '')
# load data
df_2 = load_data(name_fully_observed)
MCAR_30_2 <- load_data(name_MCAR_30)
MCAR_45_2 <- load_data(name_MCAR_45)
MAR_30_2 <- load_data(name_MAR_30)
MAR_45_2 <- load_data(name_MAR_45)
View(df_1)
View(df_2)
View(MAR_30_1)
View(MAR_45_1)
View(MCAR_30_1)
View(MCAR_45_1)
View(df_2)
View(MAR_30_2)
View(MAR_45_2)
View(MCAR_30_2)
View(MCAR_45_2)
View(MCAR_30_1)
View(MCAR_30_2)
View(MAR_45_1)
View(MAR_45_2)
View(MAR_30_1)
View(MAR_30_2)
