library(cobalt)
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
require(MCMCpack)
library(abind)
library(matrixStats)
library(truncnorm)
library(mvtnorm)
library(MCMCpack)
library(mnormt)
library(coda)
# sample MCAR dataset from PUMS
source("../../utils/sample_PUMS.R")
source("../../utils/make_MCAR.R")
n = 10000
missing_col = c(1,3,7,9,10,11)
missing_prob = 0.3
set.seed(0)
dummy <- sample_PUMS(n)
dummy <- make_MCAR(dummy, missing_prob)
data_name = 'fully_observed/fully_observed_1'
missing_data_name = 'MCAR_30/MCAR_30_1'
n_imputations = 5
max_nway = 3
source('../../utils/models/run_all_models.R')
run_all_models(data_name, missing_data_name, n_imputations, max_nway)
model_name = 'FOREST' # model to be tested
n_way = 3 # n_way to be tested
# calculate ground truth joint pmf
load('../../Datasets/ordinalPUMS.Rdata')
missing_col = c(1,3,7,9,10,11)
combinations = combn(1:11, n_way)
true_cont_table = c()
for (i in 1:(dim(combinations)[2])) {
variables = combinations[, i]
if (any(missing_col %in% variables)) {
# Calculate true contingency probability
dummy = c(table(df[, variables]))
dummy = dummy/sum(dummy)
true_cont_table = c(true_cont_table, dummy)
}
}
root = paste('../../Results/',model_name,'/', missing_data_name, sep = '')
dof_name = paste(root,'_dof_',n_way,'way.csv', sep = '')
q_bar_name = paste(root,'_q_bar_',n_way,'way.csv', sep = '')
u_bar_name = paste(root,'_u_bar_',n_way,'way.csv', sep = '')
b_name = paste(root,'_b_',n_way,'way.csv', sep = '')
# load in data
dof = as.array(read_csv(dof_name)[[1]])
mean_estimate = as.array(read_csv(q_bar_name)[[1]])
within_group_var = as.array(read_csv(u_bar_name)[[1]])
across_group_var = as.array(read_csv(b_name)[[1]])
total_var = (1+1/n_imputations)*across_group_var + within_group_var
total_sd = sqrt(total_var)
# Calculate quantile for 95% confidence interval from t distribution
q_alpha = qt(0.975, df = dof)
# Calculate upper and lower bound of 95% confidence interval
upper_bound = mean_estimate+q_alpha*total_sd
lower_bound = mean_estimate-q_alpha*total_sd
coverage = c(lower_bound<=true_cont_table & true_cont_table<=upper_bound)
mean(coverage[!is.na(coverage)])
# DO NOT ALTER CODE IN THIS CHUNK
# The very first time you use this R markdown file, you should install each of the packages below.
# The same goes for other packages you might decide to use
# Remember that you only need to install each R package once in R (ever -- unless you change computers).
# All you need to do whenever you need to use the package again (after restarting the R session),
# is to use the library function to call the package.
# For example, type install.packages("knitr") in the console to install the knitr package.
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h', fig.align = 'center')
knitr::opts_chunk$set(fig.cap = "",  fig.path = "Plot")
library(knitr)
library(dplyr)
library(arm)
library(pROC)
library(tidyverse)
library(MASS)
library(tigerstats)
library(leaps)
library(car)
library(rms)
require(caret)
require(e1071)
library(lme4)
library(lattice)
library(broom)
library(boot)
library(ggplot2)
library(cobalt)
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
require(MCMCpack)
library(abind)
library(matrixStats)
library(truncnorm)
library(mvtnorm)
library(MCMCpack)
library(mnormt)
library(coda)
# sample MCAR dataset from PUMS
source("../../utils/sample_PUMS.R")
source("../../utils/make_MCAR.R")
n = 10000
missing_col = c(1,3,7,9,10,11)
missing_prob = 0.3
set.seed(0)
dummy <- sample_PUMS(n)
dummy <- make_MCAR(dummy, missing_prob)
data_name = 'fully_observed/fully_observed_1'
missing_data_name = 'MCAR_30/MCAR_30_1'
n_imputations = 5
max_nway = 3
source('../../utils/models/run_all_models.R')
run_all_models(data_name, missing_data_name, n_imputations, max_nway)
model_name = 'DP' # model to be tested
n_way = 3 # n_way to be tested
# calculate ground truth joint pmf
load('../../Datasets/ordinalPUMS.Rdata')
missing_col = c(1,3,7,9,10,11)
combinations = combn(1:11, n_way)
true_cont_table = c()
for (i in 1:(dim(combinations)[2])) {
variables = combinations[, i]
if (any(missing_col %in% variables)) {
# Calculate true contingency probability
dummy = c(table(df[, variables]))
dummy = dummy/sum(dummy)
true_cont_table = c(true_cont_table, dummy)
}
}
root = paste('../../Results/',model_name,'/', missing_data_name, sep = '')
dof_name = paste(root,'_dof_',n_way,'way.csv', sep = '')
q_bar_name = paste(root,'_q_bar_',n_way,'way.csv', sep = '')
u_bar_name = paste(root,'_u_bar_',n_way,'way.csv', sep = '')
b_name = paste(root,'_b_',n_way,'way.csv', sep = '')
# load in data
dof = as.array(read_csv(dof_name)[[1]])
mean_estimate = as.array(read_csv(q_bar_name)[[1]])
within_group_var = as.array(read_csv(u_bar_name)[[1]])
across_group_var = as.array(read_csv(b_name)[[1]])
total_var = (1+1/n_imputations)*across_group_var + within_group_var
total_sd = sqrt(total_var)
# Calculate quantile for 95% confidence interval from t distribution
q_alpha = qt(0.975, df = dof)
# Calculate upper and lower bound of 95% confidence interval
upper_bound = mean_estimate+q_alpha*total_sd
lower_bound = mean_estimate-q_alpha*total_sd
coverage = c(lower_bound<=true_cont_table & true_cont_table<=upper_bound)
mean(coverage[!is.na(coverage)])
model_name = 'DP' # model to be tested
n_way = 2 # n_way to be tested
# calculate ground truth joint pmf
load('../../Datasets/ordinalPUMS.Rdata')
missing_col = c(1,3,7,9,10,11)
combinations = combn(1:11, n_way)
true_cont_table = c()
for (i in 1:(dim(combinations)[2])) {
variables = combinations[, i]
if (any(missing_col %in% variables)) {
# Calculate true contingency probability
dummy = c(table(df[, variables]))
dummy = dummy/sum(dummy)
true_cont_table = c(true_cont_table, dummy)
}
}
root = paste('../../Results/',model_name,'/', missing_data_name, sep = '')
dof_name = paste(root,'_dof_',n_way,'way.csv', sep = '')
q_bar_name = paste(root,'_q_bar_',n_way,'way.csv', sep = '')
u_bar_name = paste(root,'_u_bar_',n_way,'way.csv', sep = '')
b_name = paste(root,'_b_',n_way,'way.csv', sep = '')
# load in data
dof = as.array(read_csv(dof_name)[[1]])
mean_estimate = as.array(read_csv(q_bar_name)[[1]])
within_group_var = as.array(read_csv(u_bar_name)[[1]])
across_group_var = as.array(read_csv(b_name)[[1]])
total_var = (1+1/n_imputations)*across_group_var + within_group_var
total_sd = sqrt(total_var)
# Calculate quantile for 95% confidence interval from t distribution
q_alpha = qt(0.975, df = dof)
# Calculate upper and lower bound of 95% confidence interval
upper_bound = mean_estimate+q_alpha*total_sd
lower_bound = mean_estimate-q_alpha*total_sd
coverage = c(lower_bound<=true_cont_table & true_cont_table<=upper_bound)
mean(coverage[!is.na(coverage)])
# DO NOT ALTER CODE IN THIS CHUNK
# The very first time you use this R markdown file, you should install each of the packages below.
# The same goes for other packages you might decide to use
# Remember that you only need to install each R package once in R (ever -- unless you change computers).
# All you need to do whenever you need to use the package again (after restarting the R session),
# is to use the library function to call the package.
# For example, type install.packages("knitr") in the console to install the knitr package.
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h', fig.align = 'center')
knitr::opts_chunk$set(fig.cap = "",  fig.path = "Plot")
library(knitr)
library(dplyr)
library(arm)
library(pROC)
library(tidyverse)
library(MASS)
library(tigerstats)
library(leaps)
library(car)
library(rms)
require(caret)
require(e1071)
library(lme4)
library(lattice)
library(broom)
library(boot)
library(ggplot2)
library(cobalt)
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
require(MCMCpack)
library(abind)
library(matrixStats)
library(truncnorm)
library(mvtnorm)
library(MCMCpack)
library(mnormt)
library(coda)
# sample MCAR dataset from PUMS
source("../../utils/sample_PUMS.R")
source("../../utils/make_MCAR.R")
n = 10000
missing_col = c(1,3,7,9,10,11)
missing_prob = 0.3
set.seed(0)
dummy <- sample_PUMS(n)
dummy <- make_MCAR(dummy, missing_prob)
data_name = 'fully_observed/fully_observed_1'
missing_data_name = 'MCAR_30/MCAR_30_1'
n_imputations = 5
max_nway = 3
source('../../utils/models/run_all_models.R')
run_all_models(data_name, missing_data_name, n_imputations, max_nway)
model_name = 'DP' # model to be tested
n_way = 2 # n_way to be tested
# calculate ground truth joint pmf
load('../../Datasets/ordinalPUMS.Rdata')
missing_col = c(1,3,7,9,10,11)
combinations = combn(1:11, n_way)
true_cont_table = c()
for (i in 1:(dim(combinations)[2])) {
variables = combinations[, i]
if (any(missing_col %in% variables)) {
# Calculate true contingency probability
dummy = c(table(df[, variables]))
dummy = dummy/sum(dummy)
true_cont_table = c(true_cont_table, dummy)
}
}
root = paste('../../Results/',model_name,'/', missing_data_name, sep = '')
dof_name = paste(root,'_dof_',n_way,'way.csv', sep = '')
q_bar_name = paste(root,'_q_bar_',n_way,'way.csv', sep = '')
u_bar_name = paste(root,'_u_bar_',n_way,'way.csv', sep = '')
b_name = paste(root,'_b_',n_way,'way.csv', sep = '')
# load in data
dof = as.array(read_csv(dof_name)[[1]])
# DO NOT ALTER CODE IN THIS CHUNK
# The very first time you use this R markdown file, you should install each of the packages below.
# The same goes for other packages you might decide to use
# Remember that you only need to install each R package once in R (ever -- unless you change computers).
# All you need to do whenever you need to use the package again (after restarting the R session),
# is to use the library function to call the package.
# For example, type install.packages("knitr") in the console to install the knitr package.
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h', fig.align = 'center')
knitr::opts_chunk$set(fig.cap = "",  fig.path = "Plot")
library(knitr)
library(dplyr)
library(arm)
library(pROC)
library(tidyverse)
library(MASS)
library(tigerstats)
library(leaps)
library(car)
library(rms)
require(caret)
require(e1071)
library(lme4)
library(lattice)
library(broom)
library(boot)
library(ggplot2)
library(cobalt)
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
require(MCMCpack)
library(abind)
library(matrixStats)
library(truncnorm)
library(mvtnorm)
library(MCMCpack)
library(mnormt)
library(coda)
# sample MCAR dataset from PUMS
source("../../utils/sample_PUMS.R")
source("../../utils/make_MCAR.R")
n = 10000
missing_col = c(1,3,7,9,10,11)
missing_prob = 0.3
set.seed(0)
dummy <- sample_PUMS(n)
dummy <- make_MCAR(dummy, missing_prob)
data_name = 'fully_observed/fully_observed_1'
missing_data_name = 'MCAR_30/MCAR_30_1'
n_imputations = 5
max_nway = 3
source('../../utils/models/run_all_models.R')
run_all_models(data_name, missing_data_name, n_imputations, max_nway)
model_name = 'GAIN' # model to be tested
n_way = 2 # n_way to be tested
# calculate ground truth joint pmf
load('../../Datasets/ordinalPUMS.Rdata')
missing_col = c(1,3,7,9,10,11)
combinations = combn(1:11, n_way)
true_cont_table = c()
for (i in 1:(dim(combinations)[2])) {
variables = combinations[, i]
if (any(missing_col %in% variables)) {
# Calculate true contingency probability
dummy = c(table(df[, variables]))
dummy = dummy/sum(dummy)
true_cont_table = c(true_cont_table, dummy)
}
}
root = paste('../../Results/',model_name,'/', missing_data_name, sep = '')
dof_name = paste(root,'_dof_',n_way,'way.csv', sep = '')
q_bar_name = paste(root,'_q_bar_',n_way,'way.csv', sep = '')
u_bar_name = paste(root,'_u_bar_',n_way,'way.csv', sep = '')
b_name = paste(root,'_b_',n_way,'way.csv', sep = '')
# load in data
dof = as.array(read_csv(dof_name)[[1]])
mean_estimate = as.array(read_csv(q_bar_name)[[1]])
within_group_var = as.array(read_csv(u_bar_name)[[1]])
across_group_var = as.array(read_csv(b_name)[[1]])
total_var = (1+1/n_imputations)*across_group_var + within_group_var
total_sd = sqrt(total_var)
# Calculate quantile for 95% confidence interval from t distribution
q_alpha = qt(0.975, df = dof)
# Calculate upper and lower bound of 95% confidence interval
upper_bound = mean_estimate+q_alpha*total_sd
lower_bound = mean_estimate-q_alpha*total_sd
coverage = c(lower_bound<=true_cont_table & true_cont_table<=upper_bound)
mean(coverage[!is.na(coverage)])
model_name = 'GAIN' # model to be tested
n_way = 3 # n_way to be tested
# calculate ground truth joint pmf
load('../../Datasets/ordinalPUMS.Rdata')
missing_col = c(1,3,7,9,10,11)
combinations = combn(1:11, n_way)
true_cont_table = c()
for (i in 1:(dim(combinations)[2])) {
variables = combinations[, i]
if (any(missing_col %in% variables)) {
# Calculate true contingency probability
dummy = c(table(df[, variables]))
dummy = dummy/sum(dummy)
true_cont_table = c(true_cont_table, dummy)
}
}
root = paste('../../Results/',model_name,'/', missing_data_name, sep = '')
dof_name = paste(root,'_dof_',n_way,'way.csv', sep = '')
q_bar_name = paste(root,'_q_bar_',n_way,'way.csv', sep = '')
u_bar_name = paste(root,'_u_bar_',n_way,'way.csv', sep = '')
b_name = paste(root,'_b_',n_way,'way.csv', sep = '')
# load in data
dof = as.array(read_csv(dof_name)[[1]])
mean_estimate = as.array(read_csv(q_bar_name)[[1]])
within_group_var = as.array(read_csv(u_bar_name)[[1]])
across_group_var = as.array(read_csv(b_name)[[1]])
total_var = (1+1/n_imputations)*across_group_var + within_group_var
total_sd = sqrt(total_var)
# Calculate quantile for 95% confidence interval from t distribution
q_alpha = qt(0.975, df = dof)
# Calculate upper and lower bound of 95% confidence interval
upper_bound = mean_estimate+q_alpha*total_sd
lower_bound = mean_estimate-q_alpha*total_sd
coverage = c(lower_bound<=true_cont_table & true_cont_table<=upper_bound)
mean(coverage[!is.na(coverage)])
model_name = 'GAIN' # model to be tested
n_way = 1 # n_way to be tested
# calculate ground truth joint pmf
load('../../Datasets/ordinalPUMS.Rdata')
missing_col = c(1,3,7,9,10,11)
combinations = combn(1:11, n_way)
true_cont_table = c()
for (i in 1:(dim(combinations)[2])) {
variables = combinations[, i]
if (any(missing_col %in% variables)) {
# Calculate true contingency probability
dummy = c(table(df[, variables]))
dummy = dummy/sum(dummy)
true_cont_table = c(true_cont_table, dummy)
}
}
root = paste('../../Results/',model_name,'/', missing_data_name, sep = '')
dof_name = paste(root,'_dof_',n_way,'way.csv', sep = '')
q_bar_name = paste(root,'_q_bar_',n_way,'way.csv', sep = '')
u_bar_name = paste(root,'_u_bar_',n_way,'way.csv', sep = '')
b_name = paste(root,'_b_',n_way,'way.csv', sep = '')
# load in data
dof = as.array(read_csv(dof_name)[[1]])
mean_estimate = as.array(read_csv(q_bar_name)[[1]])
within_group_var = as.array(read_csv(u_bar_name)[[1]])
across_group_var = as.array(read_csv(b_name)[[1]])
total_var = (1+1/n_imputations)*across_group_var + within_group_var
total_sd = sqrt(total_var)
# Calculate quantile for 95% confidence interval from t distribution
q_alpha = qt(0.975, df = dof)
# Calculate upper and lower bound of 95% confidence interval
upper_bound = mean_estimate+q_alpha*total_sd
lower_bound = mean_estimate-q_alpha*total_sd
coverage = c(lower_bound<=true_cont_table & true_cont_table<=upper_bound)
mean(coverage[!is.na(coverage)])
# DO NOT ALTER CODE IN THIS CHUNK
# The very first time you use this R markdown file, you should install each of the packages below.
# The same goes for other packages you might decide to use
# Remember that you only need to install each R package once in R (ever -- unless you change computers).
# All you need to do whenever you need to use the package again (after restarting the R session),
# is to use the library function to call the package.
# For example, type install.packages("knitr") in the console to install the knitr package.
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h', fig.align = 'center')
knitr::opts_chunk$set(fig.cap = "",  fig.path = "Plot")
library(knitr)
library(dplyr)
library(arm)
library(pROC)
library(tidyverse)
library(MASS)
library(tigerstats)
library(leaps)
library(car)
library(rms)
require(caret)
require(e1071)
library(lme4)
library(lattice)
library(broom)
library(boot)
library(ggplot2)
library(cobalt)
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
require(MCMCpack)
library(abind)
library(matrixStats)
library(truncnorm)
library(mvtnorm)
library(MCMCpack)
library(mnormt)
library(coda)
# sample MCAR dataset from PUMS
source("../../utils/sample_PUMS.R")
source("../../utils/make_MCAR.R")
n = 10000
missing_col = c(1,3,7,9,10,11)
missing_prob = 0.3
set.seed(0)
dummy <- sample_PUMS(n)
dummy <- make_MCAR(dummy, missing_prob)
data_name = 'fully_observed/fully_observed_1'
missing_data_name = 'MCAR_30/MCAR_30_1'
n_imputations = 5
max_nway = 3
source('../../utils/models/run_all_models.R')
run_all_models(data_name, missing_data_name, n_imputations, max_nway)
model_name = 'GAIN' # model to be tested
n_way = 1 # n_way to be tested
# calculate ground truth joint pmf
load('../../Datasets/ordinalPUMS.Rdata')
missing_col = c(1,3,7,9,10,11)
combinations = combn(1:11, n_way)
true_cont_table = c()
for (i in 1:(dim(combinations)[2])) {
variables = combinations[, i]
if (any(missing_col %in% variables)) {
# Calculate true contingency probability
dummy = c(table(df[, variables]))
dummy = dummy/sum(dummy)
true_cont_table = c(true_cont_table, dummy)
}
}
root = paste('../../Results/',model_name,'/', missing_data_name, sep = '')
dof_name = paste(root,'_dof_',n_way,'way.csv', sep = '')
q_bar_name = paste(root,'_q_bar_',n_way,'way.csv', sep = '')
u_bar_name = paste(root,'_u_bar_',n_way,'way.csv', sep = '')
b_name = paste(root,'_b_',n_way,'way.csv', sep = '')
# load in data
dof = as.array(read_csv(dof_name)[[1]])
mean_estimate = as.array(read_csv(q_bar_name)[[1]])
within_group_var = as.array(read_csv(u_bar_name)[[1]])
across_group_var = as.array(read_csv(b_name)[[1]])
total_var = (1+1/n_imputations)*across_group_var + within_group_var
total_sd = sqrt(total_var)
# Calculate quantile for 95% confidence interval from t distribution
q_alpha = qt(0.975, df = dof)
# Calculate upper and lower bound of 95% confidence interval
upper_bound = mean_estimate+q_alpha*total_sd
lower_bound = mean_estimate-q_alpha*total_sd
coverage = c(lower_bound<=true_cont_table & true_cont_table<=upper_bound)
mean(coverage[!is.na(coverage)])
