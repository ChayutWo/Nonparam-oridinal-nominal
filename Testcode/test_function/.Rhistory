require(MCMCpack)
library(abind)
library(matrixStats)
library(truncnorm)
library(mvtnorm)
library(MCMCpack)
library(mnormt)
library(coda)
library(mice)
source('../../utils/load_data.R')
data_name = 'fully_observed/fully_observed_1'
missing_data_name = 'MCAR_30/MCAR_30_1'
n_imputations = 5
max_nway = 2
model_name = 'CART'
set.seed(0)
# data_name: the name of the full dataset without missing values to be used in GAIN
# missing_data_name: the name of the dataset with missing values to be loaded
# n_imputations: number of imputed dataset
# source all model codes
source('../../utils/models/MICE_imputation.R')
source('../../utils/models/CART_imputation.R')
source('../../utils/models/FOREST_imputation.R')
source('../../utils/models/DP_imputation.R')
source('../../utils/models/GAIN_imputation.R')
source('../../utils/models/PROBIT_imputation.R')
# load observed data and format it to be ordinal variables
df_observed = load_data(missing_data_name)
missing_col = c(1,3,7,9,10,11)
##### run MICE #####
#imputation_list = MICE_imputation(df_observed, n_imputations)
##### run CART #####
imputation_list = CART_imputation(df_observed, n_imputations)
##### run FOREST #####
#imputation_list = FOREST_imputation(df_observed, n_imputations)
##### run DP #####
#imputation_list = DP_imputation(df_observed, n_imputations)
##### run GAIN #####
#imputation_list = GAIN_imputation(data_name, missing_data_name, n_imputations, df_observed)
##### run PROBIT #####
#imputation_list = PROBIT_imputation(df_observed, n_imputations)
# calculate and save Rubin statistics
source("../../utils/calculate_statistics.R")
cal_save_stat(imputation_list, model_name, missing_data_name, max_nway)
# calculate ground truth joint pmf
n_way = 2
load('../../Datasets/ordinalPUMS.Rdata')
missing_col = c(1,3,7,9,10,11)
combinations = combn(1:11, n_way)
true_cont_table = c()
for (i in 1:(dim(combinations)[2])) {
variables = combinations[, i]
if (any(missing_col %in% variables)) {
# Calculate true contingency probability
dummy = c(table(df[, variables]))
dummy = dummy/sum(dummy)
true_cont_table = c(true_cont_table, dummy)
}
}
i = n_way
root = paste('../../Results/',model_name,'/', missing_data_name, sep = '')
dof_name = paste(root,'_dof_',i,'way.csv', sep = '')
q_bar_name = paste(root,'_q_bar_',i,'way.csv', sep = '')
u_bar_name = paste(root,'_u_bar_',i,'way.csv', sep = '')
b_name = paste(root,'_b_',i,'way.csv', sep = '')
# load in data
dof = as.array(read_csv(dof_name)[[1]])
mean_estimate = as.array(read_csv(q_bar_name)[[1]])
within_group_var = as.array(read_csv(u_bar_name)[[1]])
across_group_var = as.array(read_csv(b_name)[[1]])
total_var = (1+1/n_imputations)*across_group_var + within_group_var
total_sd = sqrt(total_var)
# Calculate quantile for 95% confidence interval from t distribution
q_alpha = qt(0.975, df = dof)
# Calculate upper and lower bound of 95% confidence interval
upper_bound = mean_estimate+q_alpha*total_sd
lower_bound = mean_estimate-q_alpha*total_sd
# should receive output of 96.16 percent
coverage = c(lower_bound<=true_cont_table & true_cont_table<=upper_bound)
mean(coverage[!is.na(coverage)])
# DO NOT ALTER CODE IN THIS CHUNK
# The very first time you use this R markdown file, you should install each of the packages below.
# The same goes for other packages you might decide to use
# Remember that you only need to install each R package once in R (ever -- unless you change computers).
# All you need to do whenever you need to use the package again (after restarting the R session),
# is to use the library function to call the package.
# For example, type install.packages("knitr") in the console to install the knitr package.
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h', fig.align = 'center')
knitr::opts_chunk$set(fig.cap = "",  fig.path = "Plot")
library(knitr)
library(dplyr)
library(arm)
library(pROC)
library(tidyverse)
library(MASS)
library(tigerstats)
library(leaps)
library(car)
library(rms)
require(caret)
require(e1071)
library(lme4)
library(lattice)
library(broom)
library(boot)
library(ggplot2)
library(cobalt)
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
require(MCMCpack)
library(abind)
library(matrixStats)
library(truncnorm)
library(mvtnorm)
library(MCMCpack)
library(mnormt)
library(coda)
library(mice)
source('../../utils/load_data.R')
data_name = 'fully_observed/fully_observed_1'
missing_data_name = 'MCAR_30/MCAR_30_1'
n_imputations = 5
max_nway = 2
model_name = 'CART'
# data_name: the name of the full dataset without missing values to be used in GAIN
# missing_data_name: the name of the dataset with missing values to be loaded
# n_imputations: number of imputed dataset
# source all model codes
source('../../utils/models/MICE_imputation.R')
source('../../utils/models/CART_imputation.R')
source('../../utils/models/FOREST_imputation.R')
source('../../utils/models/DP_imputation.R')
source('../../utils/models/GAIN_imputation.R')
source('../../utils/models/PROBIT_imputation.R')
# load observed data and format it to be ordinal variables
df_observed = load_data(missing_data_name)
missing_col = c(1,3,7,9,10,11)
##### run MICE #####
#imputation_list = MICE_imputation(df_observed, n_imputations)
##### run CART #####
imputation_list = CART_imputation(df_observed, n_imputations)
##### run FOREST #####
#imputation_list = FOREST_imputation(df_observed, n_imputations)
##### run DP #####
#imputation_list = DP_imputation(df_observed, n_imputations)
##### run GAIN #####
#imputation_list = GAIN_imputation(data_name, missing_data_name, n_imputations, df_observed)
##### run PROBIT #####
#imputation_list = PROBIT_imputation(df_observed, n_imputations)
# calculate and save Rubin statistics
source("../../utils/calculate_statistics.R")
cal_save_stat(imputation_list, model_name, missing_data_name, max_nway)
# calculate ground truth joint pmf
n_way = 2
load('../../Datasets/ordinalPUMS.Rdata')
missing_col = c(1,3,7,9,10,11)
combinations = combn(1:11, n_way)
true_cont_table = c()
for (i in 1:(dim(combinations)[2])) {
variables = combinations[, i]
if (any(missing_col %in% variables)) {
# Calculate true contingency probability
dummy = c(table(df[, variables]))
dummy = dummy/sum(dummy)
true_cont_table = c(true_cont_table, dummy)
}
}
i = n_way
root = paste('../../Results/',model_name,'/', missing_data_name, sep = '')
dof_name = paste(root,'_dof_',i,'way.csv', sep = '')
q_bar_name = paste(root,'_q_bar_',i,'way.csv', sep = '')
u_bar_name = paste(root,'_u_bar_',i,'way.csv', sep = '')
b_name = paste(root,'_b_',i,'way.csv', sep = '')
# load in data
dof = as.array(read_csv(dof_name)[[1]])
mean_estimate = as.array(read_csv(q_bar_name)[[1]])
within_group_var = as.array(read_csv(u_bar_name)[[1]])
across_group_var = as.array(read_csv(b_name)[[1]])
total_var = (1+1/n_imputations)*across_group_var + within_group_var
total_sd = sqrt(total_var)
# Calculate quantile for 95% confidence interval from t distribution
q_alpha = qt(0.975, df = dof)
# Calculate upper and lower bound of 95% confidence interval
upper_bound = mean_estimate+q_alpha*total_sd
lower_bound = mean_estimate-q_alpha*total_sd
coverage = c(lower_bound<=true_cont_table & true_cont_table<=upper_bound)
mean(coverage[!is.na(coverage)])
# DO NOT ALTER CODE IN THIS CHUNK
# The very first time you use this R markdown file, you should install each of the packages below.
# The same goes for other packages you might decide to use
# Remember that you only need to install each R package once in R (ever -- unless you change computers).
# All you need to do whenever you need to use the package again (after restarting the R session),
# is to use the library function to call the package.
# For example, type install.packages("knitr") in the console to install the knitr package.
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h', fig.align = 'center')
knitr::opts_chunk$set(fig.cap = "",  fig.path = "Plot")
library(knitr)
library(dplyr)
library(arm)
library(pROC)
library(tidyverse)
library(MASS)
library(tigerstats)
library(leaps)
library(car)
library(rms)
require(caret)
require(e1071)
library(lme4)
library(lattice)
library(broom)
library(boot)
library(ggplot2)
library(cobalt)
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
require(MCMCpack)
library(abind)
library(matrixStats)
library(truncnorm)
library(mvtnorm)
library(MCMCpack)
library(mnormt)
library(coda)
library(mice)
# sample MCAR dataset from PUMS
source("../../utils/sample_PUMS.R")
source("../../utils/make_MCAR.R")
n = 10000
missing_col = c(1,3,7,9,10,11)
missing_prob = 0.3
set.seed(0)
dummy <- sample_PUMS(n)
dummy <- make_MCAR(df, missing_prob)
# sample MCAR dataset from PUMS
source("../../utils/sample_PUMS.R")
source("../../utils/make_MCAR.R")
n = 10000
missing_col = c(1,3,7,9,10,11)
missing_prob = 0.3
set.seed(0)
dummy <- sample_PUMS(n)
dummy <- make_MCAR(df, missing_prob)
?abind
library(dplyr)
?abind
library(mice)
?abind
library(NPBayesImputeCat)
?abind
??abind
# DO NOT ALTER CODE IN THIS CHUNK
# The very first time you use this R markdown file, you should install each of the packages below.
# The same goes for other packages you might decide to use
# Remember that you only need to install each R package once in R (ever -- unless you change computers).
# All you need to do whenever you need to use the package again (after restarting the R session),
# is to use the library function to call the package.
# For example, type install.packages("knitr") in the console to install the knitr package.
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h', fig.align = 'center')
knitr::opts_chunk$set(fig.cap = "",  fig.path = "Plot")
library(knitr)
library(dplyr)
library(arm)
library(pROC)
library(tidyverse)
library(MASS)
library(tigerstats)
library(leaps)
library(car)
library(rms)
require(caret)
require(e1071)
library(lme4)
library(lattice)
library(broom)
library(boot)
library(ggplot2)
library(cobalt)
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
require(MCMCpack)
library(abind)
library(matrixStats)
library(truncnorm)
library(mvtnorm)
library(MCMCpack)
library(mnormt)
library(coda)
# sample MCAR dataset from PUMS
source("../../utils/sample_PUMS.R")
source("../../utils/make_MCAR.R")
n = 10000
missing_col = c(1,3,7,9,10,11)
missing_prob = 0.3
set.seed(0)
df <- sample_PUMS(n)
df_observed <- make_MCAR(df, missing_prob)
source('../../utils/models/PROBIT_imputation.R')
imputation_list = PROBIT_imputation(df_observed, 5)
source("../../utils/create_report.R")
create_report(imputation_list, max_nway=4, missing_col, df_observed)
# import function
library(tidyverse)
# sample MCAR dataset from PUMS
source("../../utils/sampleMCAR.R")
n = 10000
missing_col = c(1,3,7,9,10,11)
missing_prob = 0.3
set.seed(0)
dummy <- sampleMCAR(n, missing_prob)
source('../../utils/models/run_all_models.R')
# define the dataset name
root_fully_observed = 'fully_observed/fully_observed_'
root_MCAR_30 = 'MCAR_30/MCAR_30_'
root_MCAR_45 = 'MCAR_45/MCAR_45_'
root_MAR_30 = 'MAR_30/MAR_30_'
root_MAR_45 = 'MAR_45/MAR_45_'
# define simulation hyper parameter
n_imputations = 10
max_nway = 4
for (repindex in c(1)) {
if (repindex <= 100) {
# repindex 1 - 100: MCAR_30 dataset
i = repindex
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MCAR_30, i, sep = '')
}else if (repindex <= 200) {
# repindex 101-200: MCAR_45 dataset
i = repindex - 100
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MCAR_45, i, sep = '')
}else if (repindex <= 300) {
# repindex 201-300: MAR_30 dataset
i = repindex - 200
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MAR_30, i, sep = '')
}else if (repindex <= 400) {
# repindex 301-400: MAR_45 dataset
i = repindex - 300
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MAR_45, i, sep = '')
}
print(paste('>> start running:', data_name, missing_data_name))
run_all_models(data_name, missing_data_name, n_imputations, max_nway)
}
dummy <- sampleMCAR(n, missing_prob)
# import function
library(tidyverse)
# sample MCAR dataset from PUMS
source("../../utils/sampleMCAR.R")
n = 10000
missing_col = c(1,3,7,9,10,11)
missing_prob = 0.3
set.seed(0)
dummy <- sampleMCAR(n, missing_prob)
source('../../utils/models/run_all_models.R')
# define the dataset name
root_fully_observed = 'fully_observed/fully_observed_'
root_MCAR_30 = 'MCAR_30/MCAR_30_'
root_MCAR_45 = 'MCAR_45/MCAR_45_'
root_MAR_30 = 'MAR_30/MAR_30_'
root_MAR_45 = 'MAR_45/MAR_45_'
# define simulation hyper parameter
n_imputations = 10
max_nway = 4
for (repindex in c(1)) {
if (repindex <= 100) {
# repindex 1 - 100: MCAR_30 dataset
i = repindex
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MCAR_30, i, sep = '')
}else if (repindex <= 200) {
# repindex 101-200: MCAR_45 dataset
i = repindex - 100
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MCAR_45, i, sep = '')
}else if (repindex <= 300) {
# repindex 201-300: MAR_30 dataset
i = repindex - 200
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MAR_30, i, sep = '')
}else if (repindex <= 400) {
# repindex 301-400: MAR_45 dataset
i = repindex - 300
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MAR_45, i, sep = '')
}
print(paste('>> start running:', data_name, missing_data_name))
run_all_models(data_name, missing_data_name, n_imputations, max_nway)
}
setwd("~/DS_Projects/Nonparam-oridinal-nominal/Testcode/test_function")
# sample MCAR dataset from PUMS
source("../../utils/sampleMCAR.R")
for (repindex in 1:1) {
if (repindex <= 100) {
# repindex 1 - 100: MCAR_30 dataset
i = repindex
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MCAR_30, i, sep = '')
}else if (repindex <= 200) {
# repindex 101-200: MCAR_45 dataset
i = repindex - 100
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MCAR_45, i, sep = '')
}else if (repindex <= 300) {
# repindex 201-300: MAR_30 dataset
i = repindex - 200
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MAR_30, i, sep = '')
}else if (repindex <= 400) {
# repindex 301-400: MAR_45 dataset
i = repindex - 300
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MAR_45, i, sep = '')
}
print(paste('>> start running:', data_name, missing_data_name))
run_all_models(data_name, missing_data_name, n_imputations, max_nway)
}
# import function
library(tidyverse)
# sample MCAR dataset from PUMS
source("../../utils/sampleMCAR.R")
n = 10000
missing_col = c(1,3,7,9,10,11)
missing_prob = 0.3
set.seed(0)
dummy <- sampleMCAR(n, missing_prob)
source('../../utils/models/run_all_models.R')
# define the dataset name
root_fully_observed = 'fully_observed/fully_observed_'
root_MCAR_30 = 'MCAR_30/MCAR_30_'
root_MCAR_45 = 'MCAR_45/MCAR_45_'
root_MAR_30 = 'MAR_30/MAR_30_'
root_MAR_45 = 'MAR_45/MAR_45_'
# define simulation hyper parameter
n_imputations = 10
max_nway = 4
for (repindex in 1:1) {
if (repindex <= 100) {
# repindex 1 - 100: MCAR_30 dataset
i = repindex
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MCAR_30, i, sep = '')
}else if (repindex <= 200) {
# repindex 101-200: MCAR_45 dataset
i = repindex - 100
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MCAR_45, i, sep = '')
}else if (repindex <= 300) {
# repindex 201-300: MAR_30 dataset
i = repindex - 200
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MAR_30, i, sep = '')
}else if (repindex <= 400) {
# repindex 301-400: MAR_45 dataset
i = repindex - 300
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MAR_45, i, sep = '')
}
print(paste('>> start running:', data_name, missing_data_name))
run_all_models(data_name, missing_data_name, n_imputations, max_nway)
}
# import function
library(tidyverse)
# sample MCAR dataset from PUMS
source("../../utils/sampleMCAR.R")
n = 10000
missing_col = c(1,3,7,9,10,11)
missing_prob = 0.3
set.seed(0)
dummy <- sampleMCAR(n, missing_prob)
source('../../utils/models/run_all_models.R')
# define the dataset name
root_fully_observed = 'fully_observed/fully_observed_'
root_MCAR_30 = 'MCAR_30/MCAR_30_'
root_MCAR_45 = 'MCAR_45/MCAR_45_'
root_MAR_30 = 'MAR_30/MAR_30_'
root_MAR_45 = 'MAR_45/MAR_45_'
# define simulation hyper parameter
n_imputations = 10
max_nway = 4
for (repindex in 1:1) {
if (repindex <= 100) {
# repindex 1 - 100: MCAR_30 dataset
i = repindex
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MCAR_30, i, sep = '')
}else if (repindex <= 200) {
# repindex 101-200: MCAR_45 dataset
i = repindex - 100
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MCAR_45, i, sep = '')
}else if (repindex <= 300) {
# repindex 201-300: MAR_30 dataset
i = repindex - 200
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MAR_30, i, sep = '')
}else if (repindex <= 400) {
# repindex 301-400: MAR_45 dataset
i = repindex - 300
data_name = paste(root_fully_observed, i, sep='')
missing_data_name = paste(root_MAR_45, i, sep = '')
}
print(paste('>> start running:', data_name, missing_data_name))
run_all_models(data_name, missing_data_name, n_imputations, max_nway)
}
