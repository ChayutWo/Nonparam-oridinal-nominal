
---
title: "MCAR 30% missing - Probit"
output:
  pdf_document: default
  html_document:
    highlight: pygments
    theme: spacelab
---

```{r setup, echo =FALSE, include=FALSE}

```

* * *
```{r}
# sample MCAR dataset from PUMS
source("../../utils/sampleMCAR.R")
n = 10000
missing_col = c(1,3,7,9,10,11)
missing_prob = 0.3
set.seed(0)

dummy <- sampleMCAR(n, missing_prob)
```

```{r}
# clear workspace and load data
source('../../utils/models/run_all_models.R')

# define the dataset name
root_fully_observed = 'fully_observed/fully_observed_'
root_MCAR_30 = 'MCAR_30/MCAR_30_'
root_MCAR_45 = 'MCAR_45/MCAR_45_'
root_MAR_30 = 'MAR_30/MAR_30_'
root_MAR_45 = 'MAR_45/MAR_45_'

# define simulation hyper parameter
n_imputations = 10
max_nway = 4
for (repindex in 1:2) {
  if (repindex <= 100) {
    # repindex 1 - 100: MCAR_30 dataset
    i = repindex
    data_name = paste(root_fully_observed, i, sep='')
    missing_data_name = paste(root_MCAR_30, i, sep = '')
    run_all_models(data_name, missing_data_name, n_imputations, max_nway)
  }else if (repindex <= 200) {
    # repindex 101-200: MCAR_45 dataset
    i = repindex - 100
    data_name = paste(root_fully_observed, i, sep='')
    missing_data_name = paste(root_MCAR_45, i, sep = '')
    run_all_models(data_name, missing_data_name, n_imputations, max_nway)
  }else if (repindex <= 300) {
    # repindex 201-300: MAR_30 dataset
    i = repindex - 200
    data_name = paste(root_fully_observed, i, sep='')
    missing_data_name = paste(root_MAR_30, i, sep = '')
    run_all_models(data_name, missing_data_name, n_imputations, max_nway)
  }else if (repindex <= 400) {
    # repindex 301-400: MAR_45 dataset
    i = repindex - 300
    data_name = paste(root_fully_observed, i, sep='')
    missing_data_name = paste(root_MAR_45, i, sep = '')
    run_all_models(data_name, missing_data_name, n_imputations, max_nway)
  }
  print(paste('>> start running:', missing_data_name))

}


```

Test output

```{r}
missing_data_name = "MCAR_30/MCAR_30_1"
model_name = 'MICE' # model to be tested
n_way = 1 # n_way to be tested
# calculate ground truth joint pmf
load('../../Datasets/ordinalPUMS.Rdata')
missing_col = c(1,3,7,9,10,11)
combinations = combn(1:11, n_way)
true_cont_table = c()
for (i in 1:(dim(combinations)[2])) {
  variables = combinations[, i]
  if (any(missing_col %in% variables)) {
    # Calculate true contingency probability
    dummy = c(table(df[, variables]))
    dummy = dummy/sum(dummy)
    true_cont_table = c(true_cont_table, dummy)
  }
}

root = paste('../../Results/',model_name,'/', missing_data_name, sep = '')
dof_name = paste(root,'_dof_',n_way,'way.csv', sep = '')
q_bar_name = paste(root,'_q_bar_',n_way,'way.csv', sep = '')
u_bar_name = paste(root,'_u_bar_',n_way,'way.csv', sep = '')
b_name = paste(root,'_b_',n_way,'way.csv', sep = '')

# load in data
dof = as.array(read_csv(dof_name)[[1]])
mean_estimate = as.array(read_csv(q_bar_name)[[1]])
within_group_var = as.array(read_csv(u_bar_name)[[1]])
across_group_var = as.array(read_csv(b_name)[[1]])
total_var = (1+1/n_imputations)*across_group_var + within_group_var
total_sd = sqrt(total_var)
# Calculate quantile for 95% confidence interval from t distribution
q_alpha = qt(0.975, df = dof)

# Calculate upper and lower bound of 95% confidence interval
upper_bound = mean_estimate+q_alpha*total_sd
lower_bound = mean_estimate-q_alpha*total_sd

coverage = c(lower_bound<=true_cont_table & true_cont_table<=upper_bound)
mean(coverage[!is.na(coverage)])
```




* * *



